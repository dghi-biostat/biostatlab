---
title: "Lab 02 (707)"
description: | 
    __Lab 02 Due:__ March 4, 2022 by 14:00 ET
    <br></br>
    __Lab 03 Due:__ March 25, 2022 by 14:00 ET
date: "`r Sys.Date()`"
output: distill::distill_article
---


```{r echo = FALSE}
# DELETE BEFORE PUBLISHING
# get data
kenya <- readRDS("C:/Users/18165/Box/2021 GLHLTH 705_707 Lab R Resources/707 Labs/707 Lab 2/r/Lab_2_kenya.rds")

kenya_ind <- readRDS("C:/Users/18165/Box/2021 GLHLTH 705_707 Lab R Resources/707 Labs/707 Lab 2/r/Lab_2_kenya[unfactored].rds")

```


```{r setup0, echo = FALSE, include = FALSE}

knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(tidyverse)
library(xaringanExtra)
library(emo)
library(ggpubr)


# used in lab?
library(stringr)
library(glm.predict)
library(lmtest)
library(biostat3)
```

```{r xaringanExtra-clipboard, echo=FALSE}
xaringanExtra::use_clipboard()
```


- tabular analysis
- summary of GLM
- CLD/CLR
- disjoint indicator variables
- log-linear and logit models


## LAB MATERIALS

### Lab 02 Goals

*	Estimate crude measures of disease frequency and 95% confidence intervals (95% CI) using generalized linear models.  
*	Estimate crude measures of effect and 95% CI using generalized linear models.  
*	Learn how to code categorical variables for models and cross tabulations, including disjoint indicator variables for categorical variables with more than 2 categories.  
*	Assess for potential confounding and effect measure modification.  
*	Learn how to properly specify a model using backward, stepwise regression techniques.  


### Lab 02 Grading scheme

[[@JOE grading scheme correct? Sakai shows it was assessed out of 60 points, but I can't figure out where the additional 5 points is coming from]]

| Competency | Points |
|:-----------|:------:|
|   .Rmd file runs without error |   10  |
|   Table 1   |   10  |
|   Table 2a  |   10   |
|   Table 2b  |   5  |
|   Table 3   |   10  |
|   Figures   |   10 (3.33 points each)  |
|   __Total__  |  __55__  |

### Data and assignment

The assignment and dataset are both available on [Sakai](sakai.duke.edu)


### Packages

* {tidyverse}
* {fastDummies}
* {lmtest}
* {biostat3}

# Competencies

The following sections contain the competencies and code that you will need to complete labs 2 and 3.

## Tabular analysis (frequency counts)

You will generate the values for tabular analysis the same code as we used last semester. Please refer to last semester's lab 1 resource guide for guidance:

[Link to 705 lab 1, tabular analysis](https://dghi-biostat.github.io/biostatlab/lab_1.html#cross-tabulation-with-group_by-and-summarize)


## Summary of GLM

GLM (or Generalized Linear Models) are a family of modeling methods that can fit linear and non-linear models. They can be classified according to the distribution of the outcome (i.e. dependent/response) variable and the link function which specifies the relationship between the dependent variable (Y) and a linear combination of covariates ($\beta_1$...$\beta_i$), as summarized below.



| Outcome | Regression Model | Distribution | Link ($g(Y)$) | Form |
|:--------|:-----------------|:-------------|:------------|:-----|
| Continuous| linear | Normal | identity | $Y = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Binary| linear risk | binomial | identity | $R = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | binomial | log | $ln(R) = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | binomial | logit | $logit(R) = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | Poisson | log | $ln(Y) = \beta_0 + \beta_1X_1...\beta_kX_k$|

In the table above:

+ __Y__ = a continuous dependent variable (outcome) or count variable (for Poisson models)
+ __R__ = a probability of a binomial outcome, e.g. risk (incidence proportion) or prevalence
+ __Distribution__ refers to the outcome variable
+ __Link__: the functional relation between the dependent variable and the linear combination of covariates (which is referred to as the linear predictor: $\beta_0 + \beta_1X_1 + \beta_kX_k$)

#### Additional resources:

Here is a PDF of model forms and estimation for linear, log and logit risk models:
[link](files/lab02_modelforms.pdf)

## Confidence Limit Difference and Ratios (CLD/CLR)

Confidence Limit Difference (CLD) and Confidence Limit Ratio (CLR) are quick and useful measures of the precision of a parameter estimate and make it easier to compare estimates across studies. For example, two studies may report similar point estimates, but one may have a much wider 95% CI, meaning its value is less precise.


* $CLD = [upper\ 95\%\ CI] - [lower\ 95\%\ CI]$
* $CLR = \frac{[upper\ 95\%\ CI]}{[lower\ 95\%\ CI]}$


## R Commands for models

### Generate predicted values from log risk models

[TODO]

### Generate contrasts from CI from GLM models
[TODO]

## Nominal, ordinal, and disjoint indicator variables

Categorical variables can be represented as having values 1, 2, 3, …, but one must be careful with such representations. Nominal variables have no inherent ordering (e.g., male = 0, female = 1, Kleinfelter’s = 2) and ordinal variables may be qualitatively ordered but may not have uniform linear spacing (e.g., low = 0, medium = 1, high = 2). Including such variables in models as linear terms means that the model is mis-specified and can lead to erroneous inference because the relationship between the outcome and categorical is assumed to be linear.

### What is a disjoint indicator

Disjoint indicator (a.k.a., dummy) variables derived from nominal or ordinal categories removes the linear assumption and allows more flexibility in the shape of the outcome-predictor association.

Disjoint indicator variables are derived from categoricals by generating k new variables, one for each of the k levels of the categorical, as illustrated in the table below. You could leave out one of the indicator variables (the reference level), but I prefer to code all levels to allow flexibility in changing the reference level as needed.


| Original Coding|   Original Labels      |   `ed_none`   | `ed_primary`  | `ed_post`   |
|:---------------|:-----------------------|:-------------:|:-------------:|:-----------:|
|`education == 0` | no primary school      | 1             | 0             | 0           |
|`education == 1` | primary school only    | 0             | 1             | 0           |
|`education == 2` | post-primary education | 0             | 0             | 1           |

### Example of indicators in a model

Here, we will build a linear risk regression model for education, coded with indicators

* Risk(preterm | education) = $\beta_0 + \beta_1X_1 + \beta_2X_2$
   
    where X~1~ = `ed_primary` and X~2~ = `ed_post` and the referent category is no primary school


* In this model
    + No education:   $R_0 = [\beta_0 + 0*\beta_1 + 0*\beta_2] = \beta_0$
    + Primary school: $R_0 = [\beta_0 + 1*\beta_1 + 0*\beta_2] = \beta_0 + \beta_1$
    + Post primary:   $R_0 = [\beta_0 + 0*\beta_1 + 1*\beta_2] = \beta_0 + \beta_2$  
    
\n
* To calculate RDs with "no primary school" as the reference group and "primary school only" as the index group:

    __RD[primary vs. no primary]:__

$$
\begin{eqnarray}
&=& R_1 - R_0\\
&=& [\beta_0 + 1*\beta_1 + 0*\beta_2] - [\beta_0 + 0*\beta_1 + 0*\beta_2]\\
&=& [\beta_0 + \beta_1] - [\beta_0] = \beta_1
\end{eqnarray}
$$

* To calculate RDs with "no primary school" as the reference group and "post-primary education" as the index group:

    __RD[post-primary vs. no primary]:__

$$
\begin{eqnarray}
&=& R_2 - R_0\\
&=& [\beta_0 + 0*\beta_1 + 1*\beta_2] - [\beta_0 + 0*\beta_1 + 0*\beta_2]\\
&=& [\beta_0 + 1* \beta_2] - [\beta_0] = \beta_2
\end{eqnarray}
$$

* RR and OR are calculated similarly

### Generate indicator variables in R:

There are at least 3 ways to make or model disjoint indicator variables in R.

#### Option 1: Manual indicator variables

For this lab, we would like you to manually construct indicator variables. You can use `mutate()` and `case_when()` or `ifelse()` to create conditional statements that transform your nice categorical variables to a matrix of ones and zeroes. Here is an example using `education` in our data frame:

```{r echo = TRUE, eval = FALSE}

kenya <- kenya %>%
  mutate(
        education_0 = ifelse(education == "No primary", 1, 0),
        education_1 = ifelse(education == "Primary only", 1, 0),
        education_2 = ifelse(education == "Post-primary", 1, 0))


```


This has created three new binary variables, `education_0`, `education_1`, and `education_2`, that each indicate the presence or absence of that specific education level for each individual in the data.

#### Option 2: `fastDummies`

[@Joe did we decide that we want to introduce fastDummies for this lab?]

https://www.marsja.se/create-dummy-variables-in-r/


#### Option 3: `factor()`

__NOT RECOMMENDED FOR THIS LAB__ (This is what we did in 707 lab 1).

The functions `glm()` and `lm()` automatically treat `factor` type variables as disjoint indicator variables. 

Remember last semester? 

<aside>
I sure don't
</aside>

Remember when we talked about the importance of setting a "reference" category? That concept applies here too. When doing regressions on disjoint categorical variables, we need a baseline against which we might compare the other levels of that variable.

The lowest level of a factor-type variable is treated as the reference category (in regressions, the intercept or $\beta_0$)

We can change the reference category of a given `factor` variable by directly setting the levels when constructing the factor (using `levels = c()`).

If we need to change the levels of a factor, we can do so with `relevel()`.

Here, we see our current levels of `education`, in order from 0 to 2:

```{r echo = TRUE, eval = FALSE}
levels(kenya$education)

#> [1] "No primary"   "Primary only" "Post-primary"

```

Say we wanted to set `"Post-primary"` as our reference category. We could do that with `relevel()`

```{r echo = TRUE, eval = FALSE}
kenya$education1 <- relevel(kenya$education, ref = "Post-primary")

levels(kenya$education)

#> [1] "Post-primary" "No primary"   "Primary only"
```




## Log-linear and Logit models with `glm()`

[[TODO]]

Note: [this SO question](https://stackoverflow.com/questions/41384075/r-calculate-and-interpret-odds-ratio-in-logistic-regression) and [this stackexchange query](https://stats.stackexchange.com/questions/8661/logistic-regression-in-r-odds-ratio) are helpful here

### `family = ` and `link = `

```{r eval = FALSE}
fit_log <- glm(y ~ x, family = 'binomial'(link = 'log'), data = df)

fit_logit <- glm(y ~ x, family = 'binomial'(link = 'logit'), data = df)
```


### Extract estimates of RR and OR with `exp()`



## Categorical vs. Continuous Coding

Some exposure variables may be either analyzed as continuous or categorized according to:

* customary or clinical cut points (e.g., body mass index (BMI)  
* categories based on values used to classify people as ‘underweight’, ‘normal’, ‘overweight’ or ‘obese’)  
* empirical cut points (e.g. tertiles or quartiles), a priori cut points relevant to biologic mechanisms  
* potential public health interventions  
* other factors of interest or by cut points used commonly in the literature (this would allow comparisons between your results and what has been published previously). 

The least restrictive way to model continuous variables would be to estimate separate risks for each value (e.g. each year of maternal age). However, this approach would yield highly imprecise estimates and is not recommended.


## Graphing risks versus exposures: categorical vars

[[TODO]]

## Assess effect measure modification

[[TODO]]

## The Likelihood Ratio Test (LRT)

In general, the LRT can be used to determine whether a larger model with extra variable(s) fits the data better than a smaller model without the extra variable(s) (e.g., 2 models with and without an interaction term or 2 models with and without age as a term).

Specifically, the LRT statistic tests the null hypothesis that a larger model maximizes the likelihood of the observed data no better than a reduced model that includes fewer covariates.

Critical point – the models must be strictly comparable, so

* The variables in the reduced model must be a strict subset of those in the larger model
* The observations (e.g., people) in both models must be identical; the models are not strictly comparable if you have missing data in a variable included in the larger model because you are making estimates on different datasets
* If either of these conditions is not met, the LRT is invalid because you are comparing apples to oranges.

In this section of the lab, we will use the LRT to determine whether a model that allows effect estimates to vary across covariate strata (heterogeneity) fits the data better than a model that assumes a constant RD, RR or OR (homogeneity or constancy).

### Calculate manually

The likelihood ratio test statistic is 2X the difference between the log likelihoods of (the reduced model minus the full model):

$$
\begin{eqnarray}
LRT\ Statistic &=& (-2*LogLikelihood(reduced\_model)) - (-2*LogLikelihood(full\_model)) \\
&=& (Deviance(reduced\_model) - (Deviance(full\_model))
\end{eqnarray}
$$

The LRT statistic is distributed as a Chi-square with degrees of freedom:

$df = (# variables in full model) – (# variables in the reduced model)$

$$
df = k_{full\ model} - k_{reduced\ model}
$$

Where *k* is the number of variables in the model.

#### Extract log-likelihood from model:

If you're curious, you can run this calculation in R. To do this, we need to first extract the log likelihood from each of our models.

You can do this with the command `logLik()`:

```{r echo = TRUE, eval = FALSE}
logLik(model)
```

The output of `logLik()` can then be plugged into the equation above.

### Calculate in R with `lrtest()`

You can use the `lrtest()` command from the package {lmtest} to perform a likelihood ratio test comparing the two models.

If they aren't already stored in the R environment, run your full model and reduced model and assign them a variable name. For example:

```{r echo = TRUE, eval = FALSE}
lm_reduced <- glm(preterm ~ smoker + pnc, data = kenya, family = "binomial"(link = "identity"))

lm_full <- glm(preterm ~ smoker + pnc + smoker*pnc, data = kenya, family = "binomial"(link = "identity"))
```

Then perform the likelihood ratio test by plugging both models into the command:

```{r echo = TRUE, eval = FALSE}
lrtest(lm_reduced, lm_full)
```


## Evaluating the validity-precision trade-off assuming constancy

TODO -- @Joe, I almost feel like this part of the guide would be better off as its own standalone document or webpage. What do you think? Just seems that this really useful information would get buried on the help page. Maybe would be useful to think about how students view this webpage...are they accessing it to get help with code, or does it also provide vital information on how to interpret a given test.
