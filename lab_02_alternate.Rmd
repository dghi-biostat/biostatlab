---
title: "Lab 02 (707)"
description: |
    __Lab 02 Due:__ March 4, 2022 by 14:00 ET
    __Lab 03 Due:__ March 25, 2022 by 14:00 ET
date: "`r Sys.Date()`"
output: distill::distill_article
---


```{r}
# DELETE BEFORE PUBLISHING
# get data
kenya <- readRDS("C:/Users/18165/Box/2021 GLHLTH 705_707 Lab R Resources/707 Labs/707 Lab 2/r/Lab_2_kenya.rds")

kenya_ind <- readRDS("C:/Users/18165/Box/2021 GLHLTH 705_707 Lab R Resources/707 Labs/707 Lab 2/r/Lab_2_kenya[unfactored].rds")
 

```


```{r setup0, echo = FALSE, include = FALSE}

knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(tidyverse)
library(xaringanExtra)
library(emo)
library(ggpubr)


# used in lab?
library(stringr)
library(glm.predict)
library(lmtest)
library(biostat3)
```

```{r xaringanExtra-clipboard, echo=FALSE}
xaringanExtra::use_clipboard()
```



### Lab 02 Goals

*	Estimate crude measures of disease frequency and 95% confidence intervals (95% CI) using generalized linear models.  
*	Estimate crude measures of effect and 95% CI using generalized linear models.  
*	Learn how to code categorical variables for models and cross tabulations, including disjoint indicator variables for categorical variables with more than 2 categories.  
*	Assess for potential confounding and effect measure modification.  
*	Learn how to properly specify a model using backward, stepwise regression techniques.  


### Lab 02 Grading scheme

[[@JOE grading scheme correct? Sakai shows it was assessed out of 60 points, but I can't figure out where the additional 5 points is coming from]]

| Competency | Points |
|:-----------|:------:|
|   .Rmd file runs without error |   10  |
|   Table 1   |   10  |
|   Table 2a  |   10   |
|   Table 2b  |   5  |
|   Table 3   |   10  |
|   Figures   |   10 (3.33 points each)  |
|   __Total__  |  __55__  |

### Data and assignment

The assignment and dataset are both available on [Sakai](sakai.duke.edu)


### Packages

* {moments}
* {car}
* {tidyverse}




# Competencies




# Tabular analysis (frequency counts)

[Link to lab from 705:](https://dghi-biostat.github.io/biostatlab/lab_1.html#cross-tabulation-with-group_by-and-summarize)







# Summary of GLM

GLM (or Generalized Linear Models) are a family of modeling methods that can fit linear and non-linear models. They can be classified according to the distribution of the outcome (i.e. dependent/response) variable and the link function which specifies the relationship between the dependent variable (Y) and a linear combination of covariates ($\beta_1$...$\beta_i$), as summarized below.



| Outcome | Regression Model | Distribution | Link ($g(Y)$) | Form |
|:--------|:-----------------|:-------------|:------------|:-----|
| Continuous| linear | Normal | identity | $Y = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Binary| linear risk | binomial | identity | $R = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | binomial | log | $ln(R) = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | binomial | logit | $logit(R) = \beta_0 + \beta_1X_1...\beta_kX_k$|
| Continuous| linear | Poisson | log | $ln(Y) = \beta_0 + \beta_1X_1...\beta_kX_k$|

In the table above:

+ __Y__ = a continuous dependent variable (outcome) or count variable (for Poisson models)
+ __R__ = a probability of a binomial outcome, e.g. risk (incidence proportion) or prevalence
+ __Distribution__ refers to the outcome variable
+ __Link__: the functional relation between the dependent variable and the linear combination of covariates (which is referred to as the linear predictor: $\beta_0 + \beta_1X_1 + \beta_kX_k$)





# Confidence Limit Difference and Ratios (CLD/CLR)

Confidence Limit Difference (CLD) and Confidence Limit Ratio (CLR) are quick and useful measures of the precision of a parameter estimate and make it easier to compare estimates across studies. For example, two studies may report similar point estimates, but one may have a much wider 95% CI, meaning its value is less precise.


* $CLD = [upper\ 95\%\ CI] - [lower\ 95\%\ CI]$
* $CLR = \frac{[upper\ 95\%\ CI]}{[lower\ 95\%\ CI]}$






# Nominal, Ordinal, and Disjoint Indicator variables

### The issue with ordered categories

Categorical variables can be represented as having values 1, 2, 3, …, but one must be careful with such representations. Nominal variables have no inherent ordering (e.g., male = 0, female = 1, Kleinfelter’s = 2) and ordinal variables may be qualitatively ordered but may not have uniform linear spacing (e.g., low = 0, medium = 1, high = 2). Including such variables in models as linear terms means that the model is mis-specified and can lead to erroneous inference because the relationship between the outcome and categorical is assumed to be linear.

### Disjoint indicator variables

Disjoint indicator (a.k.a., dummy) variables derived from nominal or ordinal categories removes the linear assumption and allows more flexibility in the shape of the outcome-predictor association.

Disjoint indicator variables are derived from categoricals by generating k new variables, one for each of the k levels of the categorical, as illustrated in the table below. You could leave out one of the indicator variables (the reference level), but I prefer to code all levels to allow flexibility in changing the reference level as needed.


| Original Coding|   Original Labels      |   `ed_none`   | `ed_primary`  | `ed_post`   |
|:---------------|:-----------------------|:-------------:|:-------------:|:-----------:|
|`education == 0` | no primary school      | 1             | 0             | 0           |
|`education == 1` | primary school only    | 0             | 1             | 0           |
|`education == 2` | post-primary education | 0             | 0             | 1           |

#### Example - linear risk regression model for education, coded with indicators

* Risk(preterm | education) = $\beta_0 + \beta_1X_1 + \beta_2X_2$
   
    where X~1~ = `ed_primary` and X~2~ = `ed_post` and the referent category is no primary school


* In this model
    + No education:   $R_0 = [\beta_0 + 0*\beta_1 + 0*\beta_2] = \beta_0$
    + Primary school: $R_0 = [\beta_0 + 1*\beta_1 + 0*\beta_2] = \beta_0 + \beta_1$
    + Post primary:   $R_0 = [\beta_0 + 0*\beta_1 + 1*\beta_2] = \beta_0 + \beta_2$  
    
\n
* To calculate RDs with "no primary school" as the reference group and "primary school only" as the index group:

    __RD[primary vs. no primary]:__

$$
\begin{eqnarray}
&=& R_1 - R_0\\
&=& [\beta_0 + 1*\beta_1 + 0*\beta_2] - [\beta_0 + 0*\beta_1 + 0*\beta_2]\\
&=& [\beta_0 + \beta_1] - [\beta_0] = \beta_1
\end{eqnarray}
$$

* To calculate RDs with "no primary school" as the reference group and "post-primary education" as the index group:

    __RD[post-primary vs. no primary]:__

$$
\begin{eqnarray}
&=& R_2 - R_0\\
&=& [\beta_0 + 0*\beta_1 + 1*\beta_2] - [\beta_0 + 0*\beta_1 + 0*\beta_2]\\
&=& [\beta_0 + 1* \beta_2] - [\beta_0] = \beta_2
\end{eqnarray}
$$

* RR and OR are calculated similarly

### Generate indicator variables in R:

There are at least 3 ways to make or model disjoint indicator variables in R. We will discuss only two of them here. To that end, we have some good news and some not-so-good news.

<aside>
If you have very specific needs, {fastDummies} might offer some options. Find [a nice tutorial here](https://www.marsja.se/create-dummy-variables-in-r/)

#### The good news: `factor()` is your friend!

The functions `glm()` and `lm()` automatically treat `factor` type variables as disjoint indicator variables. 

Remember last semester? 

<aside>
I sure don't
</aside>

Remember when we talked about the importance of setting a "reference" level? That concept applies here too. When doing regressions on disjoint categorical variables, we need a baseline against which we might compare the other levels of that variable.

We can change the reference level of a given `factor` variable by directly setting the levels when constructing the factor (using `levels = c()`)

If we need to change the levels of a factor, we can do so with `relevel()`.

Here, we see our current levels of `education`, in order from 0 to 2:

```{r echo = TRUE, eval = FALSE}
levels(kenya$education)

#> [1] "No primary"   "Primary only" "Post-primary"

```
But say we wanted to set `"Post-primary"` as our reference level. We could do that with `relevel()`

```{r echo = TRUE, eval = FALSE}
kenya$education1 <- relevel(kenya$education, ref = "Post-primary")

levels(kenya$education)

#> [1] "Post-primary" "No primary"   "Primary only"
```



#### The not-so-good news: Dummies the hard way

For this lab, we would like you to manually construct indicator variables. You can use `mutate()` and `case_when()` or `ifelse()` to create conditional statements that transform your nice categorical variables to a matrix of ones and zeroes. Here is an example using `education` in our dataset:

```{r echo = TRUE, eval = FALSE}

kenya <- kenya %>%
  mutate(
        education_0 = ifelse(education == "No primary", 1, 0),
        education_1 = ifelse(education == "Primary only", 1, 0),
        education_2 = ifelse(education == "Post-primary", 1, 0))


```






# Log-linear and Logit models with `glm()`

Note: [this SO question](https://stackoverflow.com/questions/41384075/r-calculate-and-interpret-odds-ratio-in-logistic-regression) and [this stackexchange query](https://stats.stackexchange.com/questions/8661/logistic-regression-in-r-odds-ratio) are helpful here

## `family = ` and `link = `

```{r eval = FALSE}
fit_log <- glm(y ~ x, family = 'binomial'(link = 'log'), data = df)

fit_logit <- glm(y ~ x, family = 'binomial'(link = 'logit'), data = df)
```


## Extract estimates of RR and OR with `exp()`

#### toy functions for risk difference, risk ratio, and odds ratio:
These were toy functions I wrote to speed up the coding for the lab. But show the basic steps for extracting these measures
```{r}
RD_single <- function(y, x, df) {
  fit_risk <- lm(y ~ x, data = df)
  list("linear risk regression", coef(fit_risk), "confidence interval", confint(fit_risk, 'x', level = .95))
}

RD_multi <- function(y, x, z, df) {
  fit_risk <- lm(y ~ x + z, data = df)
  list("linear risk regression", coef(fit_risk), 
       "confidence intervals",
       "level 1", confint(fit_risk, 'x', level = .95),
       "level 2", confint(fit_risk, 'z', level = .95))
}

RR_IOR_single <- function(y, x, df) {
  fit_log <- glm(y ~ x, family = 'binomial'(link = 'log'), data = df)

  fit_logit <- glm(y ~ x, family = 'binomial'(link = 'logit'), data = df)

  answer <- list("log regression", exp(coef(fit_log)),
                "log confidence intervals", exp(confint(fit_log, 'x', level = .95)[1:2]),
                "logit regression", exp(coef(fit_logit)), 
                "logit confidence intervals", exp(confint(fit_logit, 'x', level = .95)[1:2])
  )
  return(answer)
}

RR_IOR_multi <- function(y, x, z, df) {
  fit_log <- glm(y ~ x + z, family = 'binomial'(link = 'log'), data = df)

  fit_logit <- glm(y ~ x + z, family = 'binomial'(link = 'logit'), data = df)

  answer <- list("log regression", exp(coef(fit_log)),
                "log confidence interval", exp(confint(fit_log)),
                "logit regression", exp(coef(fit_logit)), 
                "logit confidence interval", exp(confint(fit_logit))
  )
  return(answer)
}
```







# NAME OF SECTION
## NAME OF SUBSECTION 1
## NAME OF SUBSECTION 2
## NAME OF SUBSECTION 3
## NAME OF SUBSECTION  ETC.



