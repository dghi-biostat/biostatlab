{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Contact your teaching team with questions",
      "author": [],
      "contents": "\r\nTODO: Names, links to websites, and contact information’\r\ncat PNG Designed By 699pic from https://pngtree.com/freepng/cute-cat_5644947.html?sol=downref&id=bef\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:20-04:00"
    },
    {
      "path": "data_dict.html",
      "title": "Data Dictionary",
      "description": "Data Dictionary for Kenya's 2008 Demographic and Health Survey.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nData Dictionary Help\r\nKenya DHS Data Dictionary (file)\r\nCentury Month Code\r\n\r\n\r\n\r\n\r\n\r\nData Dictionary Help\r\nGuidelines for Data Collection & Data Entry - Theresa A Scott, MS (Vanderbilt University)\r\nKenya DHS Data Dictionary (file)\r\n\r\n\r\n{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"caseid\",\"bord\",\"b3\",\"b4\",\"b5\",\"b7\",\"m2n\",\"m18\",\"m19\",\"v008\",\"v011\",\"v025\",\"v437\",\"v438\",\"v463z\",\"s109\"],[\"Used to uniquely identify each mother.\",\"Birth order\",\"Century month code for the date of birth of the child (see note below on century month codes).\",\"Sex of child.\",\"Whether child was alive or dead at the time of interview.\",\"Age at death of the child in completed months gives a calculated age at death from the reported information. This variable occupies three digits. BASE: Dead children (B5 = 0).\",\"Indicator of no prenatal care.\",\"Size of child as reported subjectively by the mother.\",\"Weight of child at birth given in kilograms with three implied decimal places. Divide by 1000 to produce weight in kilograms. Children who were not weighed are coded 9996\",\"Century month code of date of interview (see note on century month codes).\",\"Century month code of date of birth of the mother (see note on century month codes).\",\"Type of place of residence. \",\"Weight of the mother in kilograms at time of interview. There is one implied decimal place in the weight (decimal points are not included in the data file). To produce the weight in kilograms divide by 10.\",\"Height of the mother in centimeters at time of interview. There is one implied decimal place in the height (decimal points are not included in the data file). To produce the height in centimeters divide by 10.\",\"Indicator of no smoking.\",\"Education of the mother.\"],[\"Character\",\"Integer\",\"Integer\",\"1.   male; \\n2. female\",\"0.   dead; 1. alive\",\"Integer\",\"0.   some prenatal care; \\n1. no prenatal care\",\"1.   very large; \\n2. large; \\n3. average; \\n4. smaller than average; \\n5. very small; \\n8. don't know; \\n9. missing\",\"Integer (note implied decimal places)\",\"Integer\",\"Integer\",\"1.   urban; \\n2. rural\",\"Integer (note implied decimal places)\",\"Integer (note implied decimal places)\",\"0.   smokes something; \\n1. smokes nothing; \\n9. missing\",\"0.   did not attend school; \\n1. primary; \\n2. post-primary/vocational; \\n3. seoncdary / a-level; \\n4. college (middle level); \\n5. university\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>Variable<\\/th>\\n      <th>Description<\\/th>\\n      <th>Coding<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pagelength\":20,\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}\r\nCentury Month Code\r\nAll dates in the data file are expressed in terms of months and years and also as century month codes. A century month code (CMC) is the number of the month since the start of the century.\r\nFor example, January 1900 is CMC 1, January 1901 is CMC 13, January 1980 is CMC 961, September 1994 is CMC 1137.\r\nThe CMC for a date is calculated from the month and year as follows: CMC = (YY * 12) + MM for month MM in year 19YY.\r\nTo calculate the month and year from the CMC use the following formulae: YY = int((CMC - 1) / 12) MM = CMC - (YY * 12)\r\nFor Dates in 2000 and after the CMC is calculated as follows: CMC = ((YYYY-1900) * 12) + MM for month MM in year YYYY.\r\nTo calculate the month and year from the CMC use the following formulae: YYYY = int((CMC - 1) / 12)+1900 MM = CMC - ((YYYY-1900) * 12)\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:22-04:00"
    },
    {
      "path": "fun_dict.html",
      "title": "Function Dictionary",
      "description": "A searchable table of all relevant functions for 705 and 707 labs\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n{\"x\":{\"filter\":\"top\",\"vertical\":false,\"filterHTML\":\"<tr>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n<\\/tr>\",\"data\":[[\"Import\",\"Import\",\"Import\",\"Operator\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Explore\",\"Stats\",\"Stats\",\"Stats\",\"Stats\",\"Operator\",\"Transform\",\"Transform\",\"Transform\",\"Transform\",\"Conditional\",\"Conditional\",\"Transform\",\"Tabular analysis\",\"Transform\",\"Plot\",\"Plot\",\"Plot\",\"Plot\",\"Export\",\"Export\",\"Explore\",\"Stats\",\"Explore\",\"Transform\",\"Transform\",\"Plot\",\"Transform\",\"Explore\",\"Stats\",\"Stats\",\"Stats\",\"Stats\",\"Tabular analysis\",\"Measures of Association\",\"Measures of Association\",\"Measures of Association\",\"Measures of Association\",\"Measures of Association\",\"Measures of Association\"],[\"install.packages()\",\"library()\",\"readRDS()\",\"&lt;-\",\"head()\",\"length()\",\"ncol()\",\"nrow()\",\"dim()\",\"names()\",\"summary()\",\"skim()\",\"summarize()\",\"mean()\",\"median()\",\"sd()\",\"IQR()\",\"%&gt;%\",\"sum()\",\"mutate()\",\"round()\",\"as.integer()\",\"case_when()\",\"ifelse()\",\"factor()\",\"table()\",\"proportions()\",\"ggplot()\",\"geom_histogram()\",\"geom_boxplot()\",\"labs()\",\"ggsave()\",\"saveRDS()\",\"class()\",\"range()\",\"is.na()\",\"filter()\",\"select()\",\"facet_wrap()\",\"group_by()\",\"count()\",\"t.test()\",\"kruskal.test()\",\"chisq.test()\",\"fisher.test()\",\"CreateTableOne()\",\"flipTable()\",\"mAssoc()\",\"riskdifference()\",\"riskratio()\",\"epi.2by2()\",\"epiHomog()\"],[\"package = \\\" \\\"\",\"package\",\"file = \\\" \\\"\",null,\"object\",\"object\",\"x\",\"x\",\"x\",\"x\",\"object\",\"data frame\",\"piped data (implicit), list of summary statistics\",\"object\",\"object\",\"object\",\"object\",null,\"object\",\"piped data (implicit), name-value pairs\\nex: mutate(newColumnName = oldColumn + 1)\",\"x, digits\",\"x\",\"conditional statement ~ result, …\",\"condition, result if true, result if false\",\"column of data frame\",\"column(s) of a data frame\",\"table object, margin\",\"data, aes(x = , y = )\",\"aes(x = ), binwidth = \",\"aes(x = )\",\"title, x, y, etc.\",\"filename = \\\" \\\"\",\"object, file = \\\" \\\"\",\"object\",\"Any numeric or character objects\",\"x\",\"piped data (implicit), conditional expression\",\"piped data (implicit), column names separated by commas\",\". ~ variable\",\"piped data (implicit), column names\",\"piped data (implicit)\",\"x, y (optional)\",\"x, y (optional)\",\"x, y (optional)\",\"x, y (optional)\",\"vars, strata (optional), data\",\"table object\",\"table object with exposure-outcome in top-left\",\"a = outcome+, b = outcome-, N1 = exposed+, N0 = exposed-\",\"a = outcome+, b = outcome-, N1 = exposed+, N0 = exposed-\",\"table object with exposure-outcome in top-left\",\"table object with exposure-outcome in top-left\"],[\"The name of the package you'd like to install, in quotes\",\"Loads a package and makes it available for use in R coding environment\",\"Give a file path that points to the .rds dataset you would like to load\",\"Used to assign a name to R output, thereby saving it to your R environment for later use\",\"Returns the top 6 items from an R object, like a data frame. Specify the exact number with n = \",\"Returns the length of an R object\",\"Returns the number of columns present in x\",\"Returns the number of rows present in x\",\"Returns the dimensions of an object.\",\"Returns the names of an object (e.g. the column names of a dataset)\",\"Provides summary data of an object. For data frames, these are summary stats like mean, median, etc.\",\"Alternative to summary(). Provides a broad overview of a data frame.\",\"Can be used in combination with group_by(). Will output summary statistic for each group.\",\"Returns the mean for numeric/logical vectors. \",\"Returns the median for numeric vectors.\",\"Returns the standard deviation for numeric vectors.\",\"Returns the interquartile range for numeric vectors.\",\"The R equivalent of \\\"and then\\\". Relays a data frame from one function to the next.\",\"Returns the sum of all values present in its arguments/object\",\"Adds a new variable (name) to a dataframe according to a value, hence \\\"name-value pair\\\". \",\"Rounds the values in x to the specified number of decimal places in \\\"digits = \\\"\",\"Takes floating point numbers (those with decimals) and converts them to integers\",\"See vignette. Used within mutate() to evaluate columns on conditional (if/else) statements, and returns a result for each row.\",\"Takes three arguments: a conditional statement, the result if it's true, and the result if it's false. Can be used with mutate()\",\"Converts numberic and character variables to \\\"factor\\\" categorical variables\",\"Provides one-way, two-way, and multi-way tabulation of variables from a dataset\",\"Returns conditional proportions. margin = 1 gives row proportions. margin = 2 gives column proportions.\",\"Initializes a ggplot object.\",\"Visualize the distribution of a single continuous variable by dividing x-axis into bins. Set width of bins with binwidth = \",\"Displays boxplot of a continuous variable. Stratify boxplots by specifying a y aesthetic (\\\"aes(x = , y = )\\\"\",\"Modify title, axis, and other plot labels\",\"Takes the most recent graphic run using ggplot and saves it to a file path given to filename = . Remember to use quotes around the file path and provide the file extension (.png, .jpg, .eps, etc.)\",\"Takes a data object and saves it to the file path designated by file = \\\" \\\". Don't forget to include file extension .rds\",\"Tells you the object's type. For an entire dataframe, this means the data type in each column. \",\"Returns the minimum and maximum of all the given arguments (A-Z, lowest-highest)\",\"Used to check values as missing. Commonly used to filter() based on missing values in a given column (eg. filter(is.na(variable)) )\",\"Used to subset a data frame, where it keeps all rows that satisfies the conditional expression (returns TRUE)\",\"Used to select specific columns in a dataset. Use -variable to drop a variable from a data frame and keep the rest.\",\"Used to stratify a visualization by an extra variable.\",\"Groups a data frame by sub-groups in specified column names, at which point you can perform operations within those subgroups using summarize(n(), mean(), median(), etc.)\",\"When used along with group_by(), returns subgroup frequency counts.\",\"Takes x, a numeric vector of data values (a list of numbers, like a column in a data frame), and performs one and two-way t-tests on those vectors.\",\"Takes x, a numeric vector of data values (a list of numbers, like a column in a data frame), and performs a Kruskal-Wallis rank sum test on those vectors.\",\"Takes x, a numeric vector of data values (a list of numbers, like a column in a data frame), and performs chi-squared contingency table tests and goodness-of-fit tests\",\"Takes x, a numeric vector of data values (a list of numbers, like a column in a data frame), and performs Fisher's exact test for testing the null of independence of rows and columns in a contingency table.\",\"Takes a vector of variables, vars, from a dataset and generates summary statistics for them. If strata is given, stratifies by strata.\",\"Takes a table object generated by table() and diagonally inverts the position of its rows and columns so that the top-right is now the bottom-left, etc.\",\"Returns Measures of assocation. For 2x2 tables, returns RD, RR and OR according to referent variable. For stratified 2x2 tables, returns pooled and crude measures of association.\",\"Takes +/- outcomes by exposure and calculates risk difference and confidence intervals\",\"Takes +/- outcomes by exposure and calculates risk ratio and confidence intervals\",\"Computes summary measures of risk. When exposure variable has more than one level, use mAssoc() instead.\",\"Takes a stratified table and returns the result of a chi-square test of homogeneity on the various strata's risk differences\"],[\"utils\",\"base R\",\"base R\",\"base R\",\"utils\",\"base R\",\"base R\",\"base R\",\"base R\",\"base R\",\"base R\",\"skimr\",\"dplyr\",\"base R\",\"stats\",\"stats\",\"stats\",\"dplyr\",\"base R\",\"dplyr\",\"base R\",\"base R\",\"dplyr\",\"base R\",\"base R\",\"base R\",\"base R\",\"ggplot2\",\"ggplot2\",\"ggplot2\",\"ggplot2\",\"ggplot2\",\"base R\",\"base R\",\"base R\",\"base R\",\"dplyr\",\"dplyr\",\"ggplot2\",\"dplyr\",\"dplyr\",\"stats\",\"stats\",\"stats\",\"stats\",\"tableone\",\"epiAssist\",\"epiAssist\",\"fmsb\",\"fmsb\",\"epiR\",\"epiAssist\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>Task<\\/th>\\n      <th>Function<\\/th>\\n      <th>Arguments<\\/th>\\n      <th>Description<\\/th>\\n      <th>Package<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pagelength\":20,\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:23-04:00"
    },
    {
      "path": "help_jargon.html",
      "title": "R Jargon",
      "description": "How to talk like an R nerd. Here, we detail various R-related vocabulary, the familiarity of which will make your life a lot easier.  \n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nR Vocabulary List\r\n$\r\n#\r\nargument\r\nbase R\r\ncode chunk\r\nconsole\r\ndebugging\r\ndirectory\r\ndplyr\r\nfactor\r\nfunction\r\nggplot2\r\ngit\r\nHTML\r\nindex\r\nknit\r\nlibrary/packages\r\nmagrittr/pipe/%>%\r\nparameter\r\nreproducible expressions (reprex)\r\nstring/character\r\ntibble\r\ntidy data\r\ntidyverse\r\ntraceback\r\ntribble\r\nvector\r\nvignette\r\nWickham, Hadley\r\nYAML header\r\n\r\n\r\nDoes a pesky word keep popping up that’s given you the sneaking suspicion that you have no idea what you’re doing?\r\nI’ve got good news, but also some bad news.\r\nThe bad: The person writing this probably has no idea what they’re doing either. And unless you study computer engineering, there’s a good chance you will never really “know” what you are “doing”.\r\nThe good: A quick vocabulary lesson will help do away with that sneaking suspicion, at least temporarily.\r\nR Vocabulary List\r\nSearch this document using ctrl+f for a brief definition of that word or symbol and external links for further reading. Can’t find the word here? Try R Documentation or Google.\r\n$\r\nUsed to specify a specific variable within a list-like object (like a data.frame, a tibble, a model, an actual list created with list())\r\nExample:\r\n\r\n\r\n# this code uses head() to view the first six observations for the variable \"cyl\" in dataset \"mtcars\"\r\n\r\nhead(mtcars$cyl)\r\n#> [1] 6 6 4 6 8 6\r\n\r\n\r\n\r\n#\r\nIn a chunk of code, # is used to comment out text. This tells the R console to ignore that line. This is useful for making comments in your code.\r\nOutside of code chunks, a series of hashes on a new line, followed by a space and some text, indicate different levels for document subheadings, like this:\r\nIn R Markdown, type:\r\n# one hash\r\n## two hashes\r\n### three hashes\r\n#### four hashes\r\n##### five hashes\r\nKnitting in HTML renders as:\r\n one hash \r\n two hashes \r\n three hashes \r\n four hashes \r\n five hashes \r\nargument\r\nThe various pieces of data necessary for a function to run. Many functions have arguments with default values.\r\nFor example, for many statistical tests of significance, the significance level is set to a default of 0.95. If you don’t include this argument in your function, it will refer to the default and use it.\r\nIn a function’s documentation, under “Usage”, you can tell when an argument has a default because the argument’s name is equated to a value.\r\nAs another example, the function head() takes two main arguments, an object, x, and n, the number of observations you’d like for head() to print.\r\nGo to the help documentation for head() (?head) and find what its default is. Or maybe you already have noticed its default when you’ve run head() in your labs.\r\nbase R\r\nThese are functions that are a part of the original R programming language, and so do not require a call to a package using library().\r\nGo here to see a complete list of functions that come with the R Base Package\r\ncode chunk\r\nIn R Markdown, code chunks look like this:\r\n```{r}\r\n```\r\nAnything written between these two lines can be sent to the R Console and run as code. Anything not bound within these lines is interpreted as text, and is printed as-is in a rendered document.\r\nconsole\r\nIn lieu of running code in your R Markdown document, you can type it directly into the window that says “Console”.\r\nWhen you click “Run” on any R Markdown code, that code gets run in the Console.\r\ndebugging\r\nThe process of identifying and fixing problems in your code. A debugger is a program that walks through your code, line-by-line, allowing you to inspect elements within the environment as the code runs.\r\nThis becomes more useful when you’re writing your own functions and are confused as to why they’re behaving a certain way.\r\ndirectory\r\n“The working directory of a process is a directory of a hierarchical file system”\r\nA directory is any file folder on your computer.\r\nYour root directory is the top-most directory on your computer (in Windows, this is the folder calls “C:”, for Mac users, it’s usually labelled as “Macintosh HD”)\r\nIn R, your working directory is typically the folder that contains whatever R Project you have open.\r\nSay you have a dataset called “data.rds” in your main working directory. You can import it using any number of functions by referring to its file path as simply “data.rds”.\r\nBut say you have that dataset in a series of folders within your working directory. The folders are organized like this, which each subsequent folder inside the last, and the data file in the folder titled “data”:\r\nworking directory > try1 > fullAnalysis > data\r\nThe “file path” for referring to your data file from your working directory would be this:\r\n“try1/fullAnalysis/data/data.rds”\r\ndplyr\r\nA package that contains a set of functions that help solve “the most common data manipulation challenges”. Main functions include:\r\nmutate()\r\nselect()\r\nfilter()\r\nsummarize() (or summarise())\r\narrange()\r\nHere’s the chapter from R for Data Science\r\nYou may also find this vignette helpful\r\nfactor\r\nA data type that is the preferred way to store categorical variables in R.\r\nUsing factor(), you can convert:\r\na character to a factor: This takes all unique values of a character variable and assigns them an underlying number, or “levels”.\r\nFor example:\r\n\r\n\r\ndumplings <- c(\"momos\", \"pop tarts\", \"raviolis\", \"momos\", \"empanadas\", \"pierogis\")\r\n\r\nfactor(dumplings)\r\n#> [1] momos     pop tarts raviolis  momos     empanadas pierogis \r\n#> Levels: empanadas momos pierogis pop tarts raviolis\r\n\r\n\r\n\r\nan integer to a factor: This takes integers and makes the lowest number the base level, and the next highest 1, the next highest 2, etc. You can assign a “label” to each respective level with “labels = c()”, with a vector, c(), with the same length as the number of levels.\r\n\r\n\r\nintegers <- c(1, 2, 3, 2, 3, 2, 1)\r\n\r\nfactor(integers,\r\n       labels = c(\"chicken\", \"egg\", \"rooster\"))\r\n#> [1] chicken egg     rooster egg     rooster egg     chicken\r\n#> Levels: chicken egg rooster\r\n\r\n\r\n\r\nUnderstanding factors mostly takes time. If you want to speed that up, here’s the R for Data Science chapter on factors\r\nIn it, they reference a few articles for further reading:\r\nWrangling categorical data in R\r\nstringsAsFActors: An unauthorized biography\r\nstringsAsFactors =  – this one is kinda funny\r\nfunction\r\nA “self-contained” piece of code that takes a predefined type of input data (arguments), operates on it, and returns an output or result.\r\nggplot2\r\nThe “gg” in ggplot2 stands for “grammar of graphics”.\r\nTo get a high-level overview of ggplot2 basics, I highly recommend this introduction to data visualization.\r\nIf you’re really trying to nerd out, you can access the free full text of ggplot2: Elegant Graphics for Data Analysis by Hadley Wickham by looking it up using the Duke Library search engine and logging in with your Duke credentials\r\ngit\r\nYou may have heard of GitHub, a popular website for version control, collaboration, and code sharing.\r\nGit is the underlying software that GitHub runs on. It’s free and open source. You won’t be expected to use a Git repository for your projects in this class, but it’s nice to know what’s out there.\r\nThis massive book is available for those who would like to learn more. I think the first and second sections, “Getting Started” and “Git Basics”, are good places to start.\r\nHTML\r\nStands for HyperText Markup Language. It’s the standard language used for documents that are meant to be displayed in a web browser, and is highly customizable. When R Markdown renders to HTML, it does almost all of the heavy lifting for you.\r\nindex\r\nNot particularly important for Fall semester, but is an important concept to understand when working with data.\r\nIn programming, an index is a numerical representation of an item’s position in a sequence.\r\nIn R, indexes start at number 1 (as opposed to other languages that start at 0).\r\nYou can refer to an item’s index with [ ].\r\nLETTERS gives us a character vector of every letter of the alphabet\r\n\r\n\r\nLETTERS\r\n#> [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\"\r\n#> [16] \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\r\n\r\n\r\n\r\nWe can refer to individual letters by calling their index:\r\n\r\n\r\nLETTERS[1]\r\n#> [1] \"A\"\r\n\r\nLETTERS[5]\r\n#> [1] \"E\"\r\n\r\nLETTERS[26]\r\n#> [1] \"Z\"\r\n\r\n\r\n\r\nData Frames and Tibbles can be indexed using syntax [row, column]. So data[1,1] would call the value in the first row of the first column, data[2,1] would call the value in the second row of the first column, and so on.\r\nknit\r\nThe button at the top of your R Markdown document that instructs the document to render as its designated output. The standard outputs for R Markdown are HTML, Word, and PDF. But there are an ever expanding set of R Markdown outputs available to R users. This entire website was created using a document output type called “Distill”\r\nlibrary/packages\r\nI’ll quote from an answer in StackOverflow for this one:\r\n“In R, a package is a collection of R functions, data and compiled code. The location where the packages are stored is called the library.”\r\nmagrittr/pipe/%>%\r\nChapter from R for Data Science gives a nice intro.\r\nFor you nerds, here’s a history of the pipe operator in R\r\nparameter\r\nUsed interchangeably with “argument”\r\nreproducible expressions (reprex)\r\nWhen you encounter a problem in your code that you just can’t figure out, it’s often best to create a reproducible expression. This allows whoever is helping you to recreate your problem in their own R console.\r\nCreating a “reprex” often entails trimming your code to the bare essentials and isolating whatever step in your code is causing it to hit an error.\r\nIt might also be the case that you need to create toy data. To do this, you can use the following tools:\r\ntibble() to build a dataset from vectors of equal length\r\nrunif() to create a vector of n length of random floating point values\r\nseq() to create a vector of n length in a defined sequence\r\nsample() to draw n random samples, with replace = TRUE/FALSE, from a pre-existing vector\r\nx:y – use a colon to generate a series of integers from x to y\r\nc() with comma separated values to designate a vector\r\nstring/character\r\nStrings are created with either single quotes or double quotes. It indicates that a value is meant to be read as-is, rather than transformed according to R’s computational rules for numbers and logical values.\r\nFor example, writing the logical value, TRUE as a string makes it unrecognizable to R as logical:\r\n\r\n\r\na <- TRUE\r\nisTRUE(a)\r\n#> [1] TRUE\r\n\r\nb <- \"TRUE\"\r\nisTRUE(b)\r\n#> [1] FALSE\r\n\r\n\r\n\r\nAs simple as it sounds, strings are a topic of mind-numbing complexity, as the underlying encoding of text strings governs the way that code is able to interact with data as well as other code.\r\nR for Data Science gives a nice introduction to the mechanics of strings here, but hints at their wider implications in its chapter on data importation.\r\nRegular expressions (not to be confused with reproducible expressions), or regex, are their own beast, and may help you understand how databases and search engines work\r\ntibble\r\nLike a data.frame object, but with enhanced “printing”.\r\nRead this section on tibbles from R for Data Science to learn more.\r\ntidy data\r\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.” - Hadley Wickham\r\nThe first few sections in this chapter from R for Data Science gives a nice introduction.\r\nThe basic ideas behind tidy data are defined by these three rules:\r\nEach variable must have its own column\r\nEach observation must have its own row\r\nEach value must have its own cell\r\nYou can read more about the underlying theory in this article that was published in the Journal of Statistical Software.\r\ntidyverse\r\n“The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.”\r\nFamiliar packages include:\r\ndplyr\r\nggplot2\r\ntibble\r\ntraceback\r\nIf you hit an error, use traceback() to print a summary of how your program/code arrived at that error. In simple terms, it’s tracing your steps prior to your code hitting an error.\r\ntribble\r\nShort for “transposed tibble”, it’s a function that allows you to create a tibble by hand, with the syntax and subsequent output:\r\n\r\n\r\ntribble(\r\n  ~colA, ~colB, ~colC, ~colD,\r\n  \"a\",   1, \"Square\", \"orange\",\r\n  \"b\",   2, \"Circle\", \"maracuya\",\r\n  \"c\",   3, \"Rhombus\", \"cashew\"\r\n)\r\n\r\n\r\n\r\n\r\ncolA\r\ncolB\r\ncolC\r\ncolD\r\na\r\n1\r\nSquare\r\norange\r\nb\r\n2\r\nCircle\r\nmaracuya\r\nc\r\n3\r\nRhombus\r\ncashew\r\n\r\n?tribble in the R Console for more details\r\nvector\r\nA vector is a list of values, all of the same type.\r\nWe use c() to create a vector, separating items with commas when we specify them individually.\r\nThe following are all valid vectors:\r\n\r\n\r\n# a vector of numbers 1, 2, 3:\r\nc(1, 2, 3)\r\n#> [1] 1 2 3\r\n\r\n# a vector of numbers 1 through 12, and then 20:\r\nc(1:12, 20)\r\n#> [1]  1  2  3  4  5  6  7  8  9 10 11 12 20\r\n\r\n# a vector of logical values:\r\nc(TRUE, FALSE, NA, TRUE)\r\n#> [1] \"TRUE\"  \"FALSE\" \"TRUE\" \r\n\r\n# a vector of 5 values randomly drawn from a uniform distribution with min 0 and max 1:\r\nrunif(5)\r\n#> [1] 0.97420369 0.04387835 0.68818071 0.13420150 0.30322080\r\n\r\n\r\n\r\nMost operations on vectors apply to each value individually:\r\n\r\n\r\nx <- c(1:5)\r\n\r\nx + 2\r\n#> [1] 3 4 5 6 7\r\n\r\nx * 2\r\n#> [1]  2  4  6  8  10\r\n\r\n\r\n\r\nAs such, a data frame is just a list of vectors of all the same length. That list is what’s known formally as a “recursive vector”. Lists can contain other lists.\r\nThis is a somewhat complex topic. If you’re really hungry for more info, this chapter in R for Data Science is highly informative, but may be confusing at first for those without any programming background.\r\nvignette\r\nA vignette is a long-form guide to a package. It highlights a package’s main functions and their usage. Learning from vignettes is one of the best ways to self-teach yourself a skill in R.\r\nWickham, Hadley\r\nA kiwi and a statistician who probably authored 80% of the links on this page. He is known for the tidyverse, the book R for Data Science, and his twitter.\r\nYAML header\r\nA short blob of text at the top of your R Markdown document specifying things like the document’s title, time and date stamp, and the document’s output type.\r\nThe YAML header is part of what makes R Markdown such a flexible document. There are many ways to customize your R Markdown output. We won’t get into those.\r\nJust know that at the top of your R Markdown document that says output: html_document is what instructs your it to automatically knit as an HTML file.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:25-04:00"
    },
    {
      "path": "help_packages.html",
      "title": "Packages",
      "description": "Help with installing and understanding packages, at home and in the wild.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nTerminology\r\nInstalling packages\r\nLoading libraries\r\n\r\nTerminology\r\nPackages and libraries\r\nCRAN\r\nFunctions, arguments, and objects\r\nDocumentation\r\nInstalling packages\r\nPackages are collections of functions. As we’ll see shortly, we use functions as code to view, manipulate, and analyze our data.\r\nThere are packages that come built-in with R. These have names like {base}, {utils}, and {stats}.\r\nSince R is open-source, users are able to create their own packages so that other R users can use them. These packages are available in places like the Comprehensive R Archive Network (CRAN for short) and GitHub.\r\nLucky for us, packages are easily retrieved from the R Console. If you haven’t already, run the following code from your console to download the packages that we’ll be needing for Fall Semester. You only need to do this once:\r\n\r\n\r\ninstall.packages(\"tidyverse\")\r\ninstall.packages(\"skimr\")\r\ninstall.packages(\"epiR\")\r\ninstall.packages(\"devtools\")\r\ndevtools::install_github(\"potato-nathan/epiAssist\")\r\n\r\n\r\n\r\nLoading libraries\r\nTo enable R to use a package’s functions in our current project environment, we need to load the packages using the library() function.\r\nIn a fresh code chunk, call in the {tidyverse} and {skimr} packages using the following code:\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(skimr)\r\n\r\n\r\n\r\nNotice that when we install packages, we need to specify their names using quotes, but when we load them into R using library(), R recognizes them as package objects automatically, and so don’t need quotes. You can surround them with quotes and it will load all the same.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:27-04:00"
    },
    {
      "path": "help_projects.html",
      "title": "Creating a New Project",
      "description": "This page provides advice on establishing a workflow and creating new projects with RStudio\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nCreate folders to store your work\r\nCreate a New Project in RStudio\r\n\r\nIn R, we organize our work by projects. It is best practice to keep no more than one project in any single folder on your computer. First, we should establish the file folders from which we’ll be working.\r\nCreate folders to store your work\r\nIf you haven’t already, now would be a good time to:\r\nCreate a new folder on your computer called “705 Lab”.\r\nWithin that folder, create a folder for whatever lab you’re working on, “Lab X”.\r\nFinally, within that folder, create a folder for your data, called “data”\r\nSave your dataset into the folder called “data”. This helps keep things organized as the project grows.\r\nPlease make this a habit. We will expect you to do this for every lab, as it will keep your work organized and will keep you happy.\r\nCreate a New Project in RStudio\r\nNow open RStudio and take a deep breath. Don’t panic. This will all be very familiar in a few short months.\r\nInitiate a new project by going to File and clicking New Project.\r\nSelect Existing Directory:\r\nInitiate a new project in an existing directoryIn the following window, hit Browse. Navigate to the folder where you’d like to house your new project (or create a new one if you haven’t already. Open it, then hit Open.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:27-04:00"
    },
    {
      "path": "help_rstudio.html",
      "title": "Help with RStudio",
      "description": "This page provides links to introduce you to the RStudio environment.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nRStudio Basics\r\nThe R Environment\r\nManaging window panes\r\nChange RStudio color theme\r\nRMarkdown keyboard shortcuts\r\nSession information and help documentation\r\n\r\nExtended resource guide to RStudio\r\n\r\nRStudio Basics\r\nThe R Environment\r\n\r\n\r\n\r\nA: File (New project, New file > R Markdown)B: Pop-out window (also works in R Markdown)C: Manage window panesD: New fileE: Find packages, check for updates, manage environment optionsF: Find cheatsheets (dplyr, ggplot2, R Markdown)G: Current R ProjectH: Console historyI: Plot viewerJ: File pathK: Browse help documentationL: Click to return to working directory homeM: Click to expand or shrink window pane or…N: Drag to manage window size\r\nManaging window panes\r\nDid you lose track of one of your window panes? Use the View tab in the top bar to return to a view with all panes\r\n\r\nChange RStudio color theme\r\nIs the white RStudio background burning your retnas? Need a change of scenery? No need to go outside!\r\nIn the top bar, go to Tools > Global Options, and then select “Appearance”:\r\nChange appearanceRMarkdown keyboard shortcuts\r\nYou can find me mashing the following keys in Windows:\r\nShortcut\r\nKeys (Windows)\r\nKeys (MacOS)\r\nRun a line of code\r\n(With typing cursor on line) ctrl + enter\r\n(With typing cursor on line) cmd + enter\r\nRun a chunk of code\r\n(With typing cursor in chunk) ctrl + shift + enter\r\n(With typing cursor in chunk) cmd + shift + enter\r\nCreate a new chunk\r\nctrl + alt + i\r\ncmd + option + i\r\nType a pipe\r\nctrl + shift + m\r\ncmd + shift + m\r\nType an assignment operator\r\nalt + -\r\noption + -\r\nStop running\r\n(In Console) esc\r\n(In Console) esc\r\nSession information and help documentation\r\nIf for some reason your code is hitting an error, here are some useful commands you might run in your RStudio Console to help troubleshoot:\r\nFunction Documentation\r\nCommand: ?functionName\r\nWhat it does: Pulls up the documentation for whatever you type in place of functionName, and displays it in the Help window. A function’s documentation is often (but not always) the final word on how a function is meant to behave in R. It will provide information on the function’s arguments (and their default values), the resulting output (“Values”), and will give you examples of how to implement that function.\r\nSession information\r\nCommand: sessionInfo()\r\nWhat it does: If you’re experiencing issues with a certain package, maybe it’s time for an update. You can check your current version of R using this command. Find information on specific packages by using the argument ‘package = packageName’.\r\nYou can also find which version of RStudio you have by running RStudio.Version()\r\nView Traceback\r\nCommand: traceback()\r\nWhat it does: If your code keeps hanging up on an error, you can often find clues as to why it’s happening by viewing the underlying code that’s causing your code to halt. Traceback will print the list of functions that were called before the error occurred. It’s literally “tracing your steps” right before the error happened. The language itself in the traceback is usually pretty cryptic and hard to read at first. Don’t let that stop you from looking at it when you encounter problems.\r\nMemory storage information\r\nCommand: object_size()\r\nWhat it does: For the purposes of this lab, you most likely won’t need to worry about your computer’s RAM. Nevertheless, the nerds among us might find it interesting to inspect the size of an object that we’ve saved to our R Environment. Use object_size(objectName) to inspect a given object. Alternatively, inspect overall RAM usage and limitations with memory.size() and memory.limit().\r\nExtended resource guide to RStudio\r\nR Studio will be the launching pad for all of our lab assignments in this course.\r\nThe RStudio environment itself can feel overwhelming at first. Luckily, there are excellent resources already available to help get you acquainted:\r\nFor those of you who prefer to learn by reading, this website’s first tutorial, “Getting started with R/RStudio”, is a good place to start.\r\nDr. Eric Green used to run a summer workshop called “I Eat Data Science for Breakfast”. He gives a stellar tutorial to the RStudio environment starting at 10:49 in his Week 1 video.\r\n\r\n\r\n\r\nFigure 1: I Eat Data Science for Breakfast\r\n\r\n\r\n\r\nIf you were checking your email at all over the summer, you may also already be familiar with Duke Librarian, John Little, and his series called RFun. Feel free to review his video introducing the RStudio environment\r\n\r\n\r\n\r\nFigure 2: RFun with John Little\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:28-04:00"
    },
    {
      "path": "index.html",
      "title": "Biostat Lab",
      "description": "The homepage for DGHI Biostat & Epi lab assignments, help pages, and whirly gigs\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nWelcome!\r\nA quick note on R and RStudio:\r\nA reminder on broken code\r\n\r\nWelcome!\r\nThis is the DGHI Biostatistics lab assignment homepage. Save this site’s link to your bookmark browser and return here to access lab materials. Navigate to the various labs and help documents using the bar at the top of the page.\r\nA quick note on R and RStudio:\r\nFor this lab, you are going to need to download R and RStudio, a pair of free open-source softwares used for everything from data analysis to web design.\r\nA reminder on broken code\r\nDon’t hesitate to ask for help if you are having problems with software, code, etc. But be warned, your question should be specific and detailed, not just “Why won’t this line of code run?”\r\nIn my experience, unsent emails are sometimes better than (and faster) than a TA. What looks like a hairy knot in your code is often quick to untangle when you start putting things in writing. This is why we ask that any email you send be both detailed and specific.\r\nHere are some other things that seem to help get your code to work:\r\nGo for a walk (seriously, maybe you’ve been sitting for too long)\r\nGoogle your error message – there’s almost always someone else who has encountered a similar problem\r\nDon’t delete and make changes to the same line of code. Copy/paste into a new chunk. Formulate a hypothesis. Make changes. Take notes on what changed. Revise your hypothesis. Repeat.\r\nLearn the R Debugger\r\nYou might also flip through this article on commmon problems in R Markdown, which might provide some answers.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:29-04:00"
    },
    {
      "path": "lab_0.html",
      "title": "Lab 0",
      "description": "Biostatistics & Epi, Lab 0 - GLHLTH 705: Install packages, create new R project, explore a data frame, generate summary statistics, create derived variables mage and magec with mutate(), one-way and two-way frequency counts/tabulation, save a dataset. \n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nLAB MATERIALS:\r\nLab 0 Goals:\r\nTask 1: Establish a workflow\r\nCreate folders to store your work\r\nCreate a New Project in RStudio\r\n\r\nTask 2: Familiarize yourself with R Markdown\r\nTask 3: Load packages and data\r\nInstalling packages\r\nLoad libraries\r\n\r\nTask 4: Load data\r\nTask 5: Explore the dataframe\r\nTask 6: Create variable mage\r\nTask 7: Frequency distributions of mage\r\nTask 8: Create variable magec\r\nTask 9: Cross-tab of mage and magec\r\nMethod 1:\r\nMethod 2:\r\n\r\nTask 10: Save new dataset\r\n\r\nNote: This lab is not graded (i.e. does not contribute to your course evaluation, so don’t fret)\r\nLAB MATERIALS:\r\nR Markdown file for Lab 0.__ Click link to download. Fill it in with your answers to the following lab tasks. Once you’re finished, rename it as firsInitial_YourLastName_Lab0.Rmd, and submit it using the Sakai dropbox.\r\nLab_0_kenya.rds - data file available on Sakai\r\nLab 0 Goals:\r\nBy the end of this lab, you will have demonstrated a basic familiarity with the R coding environment and R Markdown files. You will be able to:\r\nStart a new project and import data\r\nUnderstand useful R terminology\r\nUse summary statistics to describe the Kenya dataset\r\nCreate a categorical variable using a continuous one\r\nGenerate histograms and boxplots using ggplot2\r\nCreate a simple cross-tabulation of two variables\r\nTask 1: Establish a workflow\r\nIn R, we organize our work by projects. It is best practice to keep no more than one project in any single folder on your computer. First, we should establish the file folders from which we’ll be working.\r\nCreate folders to store your work\r\nIf you haven’t already, now would be a good time to:\r\nCreate a new folder on your computer called “705 Lab”.\r\nWithin that folder, create a folder for this lab, called “Lab 0”.\r\nFinally, within that folder, create a folder for your data, called “data”\r\nSave the dataset titled Lab_0_kenya.rds (from Sakai) into the folder called “data”\r\nPlease make this a habit. We will expect you to do this for every lab, as it will keep your work organized and will keep you happy.\r\nCreate a New Project in RStudio\r\nNow open RStudio and take a deep breath. Don’t panic. This will all be very familiar in a few short months.\r\nInitiate a new project by going to File and clicking New Project.\r\nTODO: INSERT SCREENSHOT\r\nThen select Existing Directory and hit Browse. Navigate to the folder titled Lab 0. Open it, then hit Open.\r\nTask 2: Familiarize yourself with R Markdown\r\nNow, you will open a special kind of document known as “R Markdown”. This is a text editor (like Word or Google Docs), but with a twist. You can run code within the document. This makes data analysis an interactive, iterative (and therefore fun?) process that usually looks like this:\r\nWrite some code intended to transform your data\r\nRun the code\r\nObserve how your dataset behaved\r\n(Optional) Take a few notes\r\nTweak code\r\nRepeat\r\nFor each lab, we will provide you with a skeleton Markdown file on Sakai. If you haven’t already, download that file (“lab0_705_fall2021.Rmd”) and save it to your folder called “Lab 0”.\r\nNow open the file in RStudio. You can just double-click on it from the file folder. It will appear, but might feel a little pinched. Luckily, RStudio allows Markdowns to pop-out.\r\nClick the white square at the top of the file that (circled in red in the photo below) to do just that:\r\nPop-outTask 3: Load packages and data\r\nInstalling packages\r\nPackages are collections of functions. As we’ll see shortly, we use functions as code to view, manipulate, and analyze our data.\r\nThere are packages that come built-in with R. These have names like {base}, {utils}, and {stats}.\r\nSince R is open-source, users are able to create their own packages so that other R users can use them. These packages are available in places like the Comprehensive R Archive Network (CRAN for short) and GitHub.\r\nLucky for us, packages are easily retrieved from the R Console. If you haven’t already, run the following code from your console to download the packages that we’ll be needing for this semester:\r\n\r\n\r\ninstall.packages(\"tidyverse\")\r\ninstall.packages(\"skimr\")\r\ninstall.packages(\"epiR\")\r\ninstall.packages(\"devtools\")\r\ndevtools::install_github(\"potato-nathan/epiAssist\")\r\n\r\n\r\n\r\nLoad libraries\r\nTo enable R to use a package’s functions in our current project environment, we need to load the packages using the library() function.\r\nIn a fresh code chunk, call in the {tidyverse} and {skimr} packages using the following code:\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(skimr)\r\n\r\n\r\n\r\nNotice that when we install packages, we need to specify their names using quotes, but when we load them into R using library(), R recognizes them as package objects automatically, and so don’t need quotes. You can surround them with quotes and it will load all the same.\r\nTask 4: Load data\r\nYou will use the dataset Lab_0_kenya.rds for this lab. You’ve hopefully already saved this lab’s dataset to the folder Lab 0 > data. You will use the function readRDS() to import the data file from your computer’s folder.\r\nSince our project is located within the folder called “Lab 0”, our computer will automatically look within that folder for the data.\r\nAll we need to do is specify that it’s in the folder called “data”.\r\nUse the following code to load your data into R and give it the name kenya.\r\n\r\n\r\nkenya <- readRDS('data/Lab_0_kenya.rds')\r\n\r\n\r\n\r\nThe <- is called the Assignment Operator. We can use it to assign names to objects in our coding environment:\r\nWe can use our assignment operator for characters, numbers, logical operators, etc.:\r\n\r\n\r\nfruit <- c(\"oranges\", \"papayas\", \"apricots\")\r\n\r\nnumber <- 99\r\n\r\nlogical <- FALSE\r\n\r\n\r\n\r\nNow that the above values are stored in our environment, we can use them in other functions or operations:\r\n\r\n\r\npaste(fruit, \"are orange\", sep = \" \")\r\n\r\n\r\n[1] \"oranges are orange\"  \"papayas are orange\"  \"apricots are orange\"\r\n\r\nnumber + 1\r\n\r\n\r\n[1] 100\r\n\r\nisTRUE(logical)\r\n\r\n\r\n[1] FALSE\r\n\r\nWe’ve done the same thing with our dataset, giving it the name kenya. Use the function head() to view the first six rows in the dataset:\r\n\r\n\r\nhead(kenya)\r\n\r\n\r\n\r\nTask 5: Explore the dataframe\r\nFamiliarize yourself with the data by using the commands ncol(), nrow(), class(), names() and skim().\r\nAre there any string/character variables?\r\nAre there any variable or value labels?\r\nDo any variables have notes?\r\nSimilar to the function head(), we can feed our kenya data frame to various functions that tell us other useful information about it.\r\nUse ncol() to print the number of columns in our data frame\r\nUse nrow() to print the number of rows\r\nUse class() to view each variable’s “type”\r\nUse names() to view each variable’s name.\r\nUse skim() to print summary statistics for each variable in the data frame\r\nTask 6: Create variable mage\r\nUsing a pipe and the mutate() function, create a new variable, mage for mother’s age (as an integer) at the time of each child’s birth (note – some of these mothers have had multiple children). This is calculated from variables b3 (month code of child’s birth) and v011 (month code of mother’s birth). The difference between the values of these variables is months, so divide by 12 to get years. See the data dictionary for a more detailed description of month codes and how to use them. Use the as.integer() function within your mutate() operation to truncate the calculated values for mage to integers.\r\nThe mutate() function works with the following syntax.\r\n\r\n\r\n# don't forget to write over your old dataframe with the new \"mutated\" one\r\ndata <- data %>%\r\n  mutate(newVariableName = (Variable1 - Variable2))\r\n\r\n\r\n\r\nTask 7: Frequency distributions of mage\r\nSuppose you want to break down mage into three categories. First, look at the frequency distribution (one-way frequency table) for mage to see where you might draw lines for your categories using the table() command.\r\ntable() works by identifying unique values within a variable, and then counts them.\r\nIt works on character variables, categorical (factor) variables, and even numbers.\r\nWe can tell R to look at specific variables inside our dataframe with the $ sign. The syntax looks like this: dataframeName$variableName\r\nWe must also provide the argument useNA = 'always' to our table() function in order to include NA values in the tabulation.\r\nUse table() to look at mage, then consider the following questions:\r\nAre there any missing values for age? If so, how many?\r\nWhich range of ages appear the most frequently in mage?\r\nTask 8: Create variable magec\r\nUsing mage, generate a new variable with three categories: <18, 18-39, and ≥ 40, naming the new variable magec (__m__other’s age __c__ategorical). Set the values for magec to be 0,1,2, where 0 corresponds to the youngest age group (<18). Recommended steps:\r\nFirst, don’t forget to use the assignment operator to save your changes to the kenya data frame.\r\nThen, use a pipe (%>%) and then mutate() to create a new variable, magec,\r\nwithin your mutate() command, use case_when() to create a series of conditional statements that assign numbers 0, 1, and 2 to each category\r\non a new line of code, use factor() to assign labels to each level of your new variable\r\nValues:\r\n0: <18\r\n1: 18-39\r\n2: ≥ 40\r\nConvert a variable to a factor with the following syntax:\r\n\r\n\r\ndataframe$variableYouWantToFactor <- factor(dataframe$variableYouWantToFactor,\r\n                                            labels = c(\"Label for 0\", \"Label for 1\", \"Label for 2\"))\r\n\r\n\r\n\r\nTask 9: Cross-tab of mage and magec\r\nLook at a cross-tabulation (two-way table) of mage and magec to ensure that magec was created correctly. Be sure missing values were handled properly (all observations that have a missing value for mage should be assigned the R missing value “NA” for magec). Try the two separate methods for cross-tabulation, as we will be using both for separate purposes later in the semester:\r\nMethod 1:\r\nType “?table” in the console for help with how to create a 2x2 table. Note: the order of the variables in the command controls which one is in the rows and which is in the columns. Experiment to make your table readable.\r\n\r\n\r\n# example code:\r\n\r\ntable(data$x, data$y, useNA = 'always')\r\n\r\n\r\n\r\nMethod 2:\r\nWe can also use tidyverse functions to accomplish a two-way tabulation of our variables of interest. These functions will become increasingly relevant and useful, and are a big reason why R is such a popular platform for data science. We will use a pipe (%>%), group_by(), another pipe, and count() to get the same output given by table().\r\n\r\n\r\n# example code:\r\n\r\n# notice that we don't want to assign this operation to a name\r\n# we just want to view the output, hence the lack of \"data <- \"\r\ndata %>%\r\n  group_by(x, y) %>%\r\n  count()\r\n\r\n\r\n\r\nA translation of the above code to written instructions would go as follows, where bolded words represent the grammatical equivalent of our pipe, %>%:\r\n“Take dataset, data, and then group_by by variable x, then within those groups, group by variable y, and then count the values in each of our groups.”\r\nHere’s a link to learning more about pipes. Or just take a look at this tweet:\r\n\r\n\r\n\r\nTask 10: Save new dataset\r\nUsing function saveRDS(), save the new dataset in the same directory as our original data, using the following format: “firstInitial_YourLastName_lab0.rds”\r\nsaveRDS() takes two primary arguments:\r\nThe dataframe object you want to save\r\nThe location in which you’d like it saved as a .rds file\r\nDon’t forget the following:\r\nThe file locations should be in quotes, so that R knows to read it as a character string\r\nYour file should be saved in your local Lab 0 folder, data/\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:33-04:00"
    },
    {
      "path": "lab_1.html",
      "title": "Lab 1",
      "description": "Biostatistics & Epi, Lab 1 - GLHLTH 705. Create derived variables for birth order (bord5), sex (male), mheight, mweight, mbmi. Frequency histograms, boxplots, frequency table, and data dictionary.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nLAB MATERIALS:\r\nLab 1 Goals:\r\nTask 1: Load libraries & packages\r\nTask 2: Recode variables\r\nTask2a: bord5\r\nTask 2b: male\r\nTask 2c: mweight\r\nTask 2d: mheight\r\nTask 2e: mbmi\r\n\r\nTask 3: Frequency histograms\r\nTask 4: Boxplots\r\nTask 5: Frequency table (Table 1)\r\nTask 6: Data dictionary (Table 2)\r\nTask 7: Short answer\r\n\r\nLAB MATERIALS:\r\nR Markdown file for Lab 1.__ Click link to download. Fill it in with your answers to the following lab tasks. When you’re ready to submit, name it as Lab1_FirstinitialYourlastname.Rmd, and submit it using the Sakai dropbox.\r\nExcel document for Tables 1 & 2 TODO: Set up answer entry on Sakai?\r\nLab_1_kenya.rds - data file available on Sakai\r\nLab 1 Goals:\r\nGenerate derived variables\r\nIdentify and recode special values\r\nRun descriptive statistics for continuous and categorical variables\r\nGenerate graphics for continuous variables\r\nGenerate a complete data dictionary\r\nTask 1: Load libraries & packages\r\nUse the dataset Lab_1_kenya.rds for this assignment.\r\nYou will also need packages {skimr} and {tidyverse}\r\n** Reminder: To run a line of code, use the shortcut ctrl + enter (Windows)/cmd + enter (Mac)\r\nTask 2: Recode variables\r\nConstruct the following derived variables using a pipe and mutate(). For each, examine the component variables for coded special values (i.e. “NA”) and be sure to set derived variable values appropriately. Label all variables and the coded values for the categorical ones using the factor() command.\r\nHelp with pipes\r\nHelp with factors\r\nTask2a: bord5\r\nbord5: Dichotomous variable indicating birth order of the child. [0=current child was 1st through 4th in the birth order, 1=current child was later than 4th in the birth order]. Based on variable bord (birth order).\r\nTask 2b: male\r\nmale: Dichotomous categorical variable indicating that the child is male [0=female, 1=male]. Based on variable b4.\r\nTask 2c: mweight\r\nmweight: Continuous variable for maternal weight at time of interview (in kilograms). Based on variable v437. Note that v437 contains 1 implied decimal place. Divide by 10 to get kilograms.\r\nTask 2d: mheight\r\nmheight: Continuous maternal height at time of interview (in meters). Based on variable v438. Note that this variable is in centimeters and also contains 1 implied decimal place.\r\nTask 2e: mbmi\r\nmbmi: maternal body mass index (BMI). Weight (kilograms) / height^2 (meters).\r\nTask 3: Frequency histograms\r\nGenerate frequency histograms of mweight, mheight and mbmi. Put meaningful axis labels and a title on each figure.\r\nHelp with histograms in ggplot2\r\nTask 4: Boxplots\r\nGenerate boxplots of mweight, mheight, and mbmi for the levels of magec. Put meaningful axis labels and a title on each figure.\r\nHelp with boxplots in ggplot2\r\nTask 5: Frequency table (Table 1)\r\nFill in Table 1 with the frequency counts and percentages for the levels of the 3 categorical variables you have generated. Calculate percentages only for the non-missing values. Round percentages to 1 decimal place.\r\nWe would like you to use a pipe (%>%) with group_by() and summarize() to generate summary statistics.\r\ngroup_by() works by grouping rows by categorical variables. It then allows a function like summarize() to calculate summary statistics on those sub-groups, including percentages and frequency counts.\r\nAs an example, we can use the mtcars dataset available within RStudio:\r\n\r\n\r\nhead(mtcars)\r\n\r\n\r\n\r\n\r\n\r\nmpg\r\ncyl\r\ndisp\r\nhp\r\ndrat\r\nwt\r\nqsec\r\nvs\r\nam\r\ngear\r\ncarb\r\nMazda RX4\r\n21.0\r\n6\r\n160\r\n110\r\n3.90\r\n2.620\r\n16.46\r\n0\r\n1\r\n4\r\n4\r\nMazda RX4 Wag\r\n21.0\r\n6\r\n160\r\n110\r\n3.90\r\n2.875\r\n17.02\r\n0\r\n1\r\n4\r\n4\r\nDatsun 710\r\n22.8\r\n4\r\n108\r\n93\r\n3.85\r\n2.320\r\n18.61\r\n1\r\n1\r\n4\r\n1\r\nHornet 4 Drive\r\n21.4\r\n6\r\n258\r\n110\r\n3.08\r\n3.215\r\n19.44\r\n1\r\n0\r\n3\r\n1\r\nHornet Sportabout\r\n18.7\r\n8\r\n360\r\n175\r\n3.15\r\n3.440\r\n17.02\r\n0\r\n0\r\n3\r\n2\r\nValiant\r\n18.1\r\n6\r\n225\r\n105\r\n2.76\r\n3.460\r\n20.22\r\n1\r\n0\r\n3\r\n1\r\n\r\nSay we want to know the frequency counts of cars with 4, 6, and 8 cylinders (variable: cyl) based on whether or not a car has an automatic or manual transmission (variable am, 0 = automatic, 1 = manual).\r\nWe can use group_by() to create subgroups according to am and cyl. Using group_by() by itself doesn’t alter the appearance of our data frame, but our observations are now implicitly grouped according to transmission type and number of cylinders.\r\n\r\n\r\nmtcars %>%\r\n  group_by(am, cyl)\r\n\r\n\r\n\r\n\r\nmpg\r\ncyl\r\ndisp\r\nhp\r\ndrat\r\nwt\r\nqsec\r\nvs\r\nam\r\ngear\r\ncarb\r\n21.0\r\n6\r\n160\r\n110\r\n3.90\r\n2.620\r\n16.46\r\n0\r\n1\r\n4\r\n4\r\n21.0\r\n6\r\n160\r\n110\r\n3.90\r\n2.875\r\n17.02\r\n0\r\n1\r\n4\r\n4\r\n22.8\r\n4\r\n108\r\n93\r\n3.85\r\n2.320\r\n18.61\r\n1\r\n1\r\n4\r\n1\r\n21.4\r\n6\r\n258\r\n110\r\n3.08\r\n3.215\r\n19.44\r\n1\r\n0\r\n3\r\n1\r\n18.7\r\n8\r\n360\r\n175\r\n3.15\r\n3.440\r\n17.02\r\n0\r\n0\r\n3\r\n2\r\n18.1\r\n6\r\n225\r\n105\r\n2.76\r\n3.460\r\n20.22\r\n1\r\n0\r\n3\r\n1\r\n\r\nWe might use summarize() to operate on these sub-groups. summarize() works with the following syntax:\r\n\r\n\r\nmtcars %>%\r\n  group_by(am, cyl) %>%\r\n  summarize(columnName = Function(variable), \r\n            anotherColumnName = anotherFunction(variable),\r\n            etc., etc....)\r\n\r\n\r\n\r\nDepending on whether our variable is categorical or continuous, we can use summary statistic functions like n() (for raw counts), mean(), sd(), median(), IQR(), min(), and max() within our summarize() function. Except for n(), which doesn’t take any arguments, the rest of these functions take a variable name.\r\nWe can start by using n() for sub-group frequency counts.\r\n\r\n\r\nmtcars %>%\r\n  group_by(am, cyl) %>%\r\n  summarize(Counts = n())\r\n\r\n\r\n\r\n\r\nam\r\ncyl\r\nCounts\r\n0\r\n4\r\n3\r\n0\r\n6\r\n4\r\n0\r\n8\r\n12\r\n1\r\n4\r\n8\r\n1\r\n6\r\n3\r\n1\r\n8\r\n2\r\n\r\nThen we can use mutate() to operate on our summary table as if it were its own data frame.\r\nWithin mutate(), we create a new variable with NewVariable =, and equate it to the following operation: Counts / sum(Counts, na.rm = TRUE) (sub-group counts divided by the sum of sub-group counts).\r\n__**Note__: na.rm = TRUE instructs the function to remove NA values from the sum of values in our sub-group.\r\n\r\n\r\nmtcars %>%\r\n  group_by(am, cyl) %>%\r\n  summarize(Counts = n()) %>%\r\n  mutate(Proportions = Counts / sum(Counts, na.rm = TRUE))\r\n\r\n\r\n\r\n\r\nam\r\ncyl\r\nCounts\r\nProportions\r\n0\r\n4\r\n3\r\n0.1578947\r\n0\r\n6\r\n4\r\n0.2105263\r\n0\r\n8\r\n12\r\n0.6315789\r\n1\r\n4\r\n8\r\n0.6153846\r\n1\r\n6\r\n3\r\n0.2307692\r\n1\r\n8\r\n2\r\n0.1538462\r\n\r\nAlso notice that we’re able to do this within one continuous pipe.\r\nTask 6: Data dictionary (Table 2)\r\nTable 2 is the data dictionary for the Kenya dataset, with columns added to annotate the variables and provide summary statistics. Using output from skim():\r\nFill in the columns in this table for the variables originally in the dataset.\r\nAdd rows for the 7 new variables that you have created in both Labs 0 and 1.\r\nTask 7: Short answer\r\nEnter your response into your own RMarkdown file\r\nExamine the range and proportion of missing values for each of the 7 variables you have created in Labs 0 and 1. Are there characteristics of any of these variables that are concerning (e.g., missing, suspicious or impossible values)? In contemplating analysis of these data, what do you think should be done with anomalous information? What effect would missing values have on the validity of your analyses (e.g., how might missing or extreme values affect inferences)? (Response no longer than 250 words, please)\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:34-04:00"
    },
    {
      "path": "lab_2.html",
      "title": "Lab 2",
      "description": "Biostatistics & Epi, Lab 2 - GLHLTH 705. Create derived variables: size, belowavg, pnc, rural, education, death, time. Close cohort. Frequency histograms, boxplots, frequency counts, and data dictionary.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nLAB MATERIALS:\r\nLab 2 Goals:\r\nTask 1: Load libraries and data\r\nTask 2: Code derived variables\r\nTask 2a: size\r\nTask 2b: belowavg\r\nTask 2c: pnc\r\nTask 2d: rural\r\nTask 2e: education\r\nTask 2f: death\r\nTask 2g: time\r\n\r\nTask 3: Close the cohort\r\nTask 3a: Exclude irrelevant observations\r\nTask 3b:\r\nTask 3c: Recode time to (time + 1)\r\nTask 3d: Save new dataset\r\n\r\nTask 4: Frequency histograms\r\nTask 5: Boxplots of time\r\nTask 6: Frequency counts and percentages (Table 1)\r\nTask 7: Update data dictionary (Table 2)\r\nTask 8: Short Answer\r\n\r\nLAB MATERIALS:\r\nR Markdown file for Lab 2. Click link to download. Fill it in with your answers to the following lab tasks. When you’re ready to submit, name it as Lab2_FirstinitialYourlastname.Rmd, and submit it using the Sakai dropbox.\r\nExcel document for Tables 1 & 2 TODO: Set up answer entry on Sakai?\r\nLab_2_kenya.rds - data file available on Sakai\r\nLab 2 Goals:\r\nGenerate derived variables\r\nIdentify and recode special values\r\nRun descriptive statistics for continuous and categorical variables\r\nGenerate graphics for continuous variables\r\nGenerate a complete data dictionary\r\nTask 1: Load libraries and data\r\nFor this assignment, use the dataset that I have supplied you – lab_2_kenya.rds. You will need the {tidyverse} package as well.\r\nTask 2: Code derived variables\r\nConstruct the following derived variables. For each, examine the component variables for missing values (e.g. ‘missing’, ‘unknown’) and be sure to set derived variable values appropriately (e.g., check to make sure that your NA values have not been mistakenly added to another category). Variables should be of the correct type. Convert all categorical variables to factors, labeling them appropriately.\r\nTask 2a: size\r\nsize: Categorical variable describing size of child at birth (subjectively described by mother). Note that greater values indicate smaller size: [1=very large, 2=larger than average, 3=average, 4=smaller than average, 5=very small]. Based on variable m18.\r\nTask 2b: belowavg\r\nbelowavg: Dichotomous variable indicating if the child’s size was below average [0= average, larger than average or very large, 1=smaller than average, very small]\r\nTask 2c: pnc\r\npnc: Dichotomous categorical variable for any prenatal care [0 = the referent category; no prenatal care; 1 = the index category; received prenatal care]. Based on variable m2n.\r\nTask 2d: rural\r\nrural: Dichotomous indicator of rural residence [0=urban, 1=rural]. Based on variable v025.\r\nTask 2e: education\r\neducation: Categorical educational level obtained by mother [create values for 0=did not attend school, 1=primary school only, 2=post-primary education]. Based on variable s109.\r\nTask 2f: death\r\ndeath: Dichotomous categorical variable for death within the first 5 years of life [0 = child alive at 5th birthday (the referent category); 1 = child died before 5th birthday (the index category)]. Based on the variables b5 (death indicator) and b7.\r\nNote: When creating this new variable, we want our conditional statement to account for two factors: Whether a child died, and if they did, whether or not that death occurred before their 5th birthday.\r\nTask 2g: time\r\ntime: Continuous variable for the age at death OR age at interview for children still alive. Based on b7 (age at death for children dead at interview); for children alive at time of interview, calculate their age using v008 (date of interview) and b3 (date of birth). Note that times are given in months.\r\nTask 3: Close the cohort\r\nCreate the equivalent of a closed cohort for the analysis of 5-year childhood mortality from this dataset . In a closed cohort, everyone must be at risk of the outcome at entry into the cohort, and all members of the cohort must remain at risk until they experience the outcome or complete the entire risk period for the outcome.\r\nA closed cohort allows for estimation of absolute (unconditional) risks and associated effect measures. For this study, the risk period for child mortality begins at birth and ends when a child dies, or when 60 months of life have been completed. I recommend completing the steps below in order to generate what we want. There are other orders in which to do this, but sometimes you will get incorrect results. If you’re adventurous, I recommend trying other ways to code this; you’ll learn a lot from that exercise.\r\nNOTE: Complete task 3 before completing the remaining tasks.\r\nTask 3a: Exclude irrelevant observations\r\nExclude those observations from the dataset where the child was alive (death=0) and follow-up time (time) was less than 60 months (think about which Boolean operator you’ll need to exclude those children). You should end up with 16,828 subjects in the dataset. In this step, you should also use an assignment operator (<-) to assign this closed cohort to a different object name. That way, you will be able to work with this dataset separately in the coming steps.\r\nTask 3b:\r\nAlso, if a child was still alive by their 5th birthday, we need to recode their time to 60 (we are censoring these observations). These children were alive at 5 years of age and so should not be counted as deaths in our analysis.\r\nTask 3c: Recode time to (time + 1)\r\nFinally, recode the time variable to indicate the month of life during which death or interview occurred (add 1 month to the current value). The range on time should now be 1 month – 61 months.\r\nTask 3d: Save new dataset\r\nSave this new dataset containing 16828 subjects (make sure to give it a new name).\r\nTask 4: Frequency histograms\r\nGenerate frequency histograms of time, overall and separately for levels of death. Put meaningful axis labels and a title on each figure.\r\nTODO: Help with histograms in ggplot2\r\nTask 5: Boxplots of time\r\nGenerate boxplots of time, overall and separately for levels of death. Put meaningful axis labels and a title on each figure.\r\nTODO: Help with boxplots in ggplot2\r\nTask 6: Frequency counts and percentages (Table 1)\r\nFill in Table 1 with the frequency counts and percentages for the levels of the new categorical variables you have generated. Calculate percentages only for the non-missing values. Round percentages to 1 decimal place.\r\nRefer to the previous lab for help on frequency counts and percentages.\r\nVariables:\r\nSize at birth (size)\r\nSize at birth categorical (belowavg)\r\nPrenatal care (pnc)\r\nResidence type (rural)\r\nMother’s education (education)\r\nDeath by 5 years (death)\r\nTask 7: Update data dictionary (Table 2)\r\nUpdate your data dictionary for the Kenya dataset, adding the newly created variables.\r\nTask 8: Short Answer\r\nExamine the range and proportion of missing for each of the variables 7 you have created in this lab. Are there characteristics of any of these variables that are concerning (e.g., missing, suspicious or impossible values)? In contemplating analysis of these data, what do you think should be done with anomalous information? What effect would missing values have on the validity of your analyses (e.g., how might missing or extreme values affect inferences)?\r\nProvide your answer to this question within your own RMarkdown file\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:35-04:00"
    },
    {
      "path": "lab_3.html",
      "title": "Lab 3",
      "description": "Biostatistics & Epi I, Lab 3 - GLHLTH 705\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nLAB MATERIALS:\r\nLab 2 Goals:\r\n\r\nLAB MATERIALS:\r\nR Markdown file for Lab 3. Click link to download. Fill it in with your answers to the following lab tasks. When you’re ready to submit, name it as Lab3_FirstinitialYourlastname.Rmd, and submit it using the Sakai dropbox.\r\nExcel document for Tables 1 & 2 TODO: Set up answer entry on Sakai?\r\nLab_3_kenya.rds - data file available on Sakai\r\nLab 2 Goals:\r\nAssess the bivariate relationships between outcome and covariables and the statistical association between the two variables\r\nEstimate the epidemiologic measures of association (risk difference, risk ratio and odds ratio) between risk factors and outcome\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:36-04:00"
    },
    {
      "path": "lab_4.html",
      "title": "Lab 4",
      "description": "Biostatistics & Epi I, Lab 4 - GLHLTH 705\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nLAB MATERIALS:\r\nLab 2 Goals:\r\n\r\nLAB MATERIALS:\r\nR Markdown file for Lab 4. Click link to download. Fill it in with your answers to the following lab tasks. When you’re ready to submit, name it as Lab4_FirstinitialYourlastname.Rmd, and submit it using the Sakai dropbox.\r\nExcel document for Tables 1 & 2 TODO: Set up answer entry on Sakai?\r\nLab_4_kenya.rds - data file available on Sakai\r\nLab 2 Goals:\r\nCalculate measures of association between birth order and child mortality by 5 years within strata of other variables\r\nAssess potential for confounding and effect modification (mediation) by those other variables.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:37-04:00"
    },
    {
      "path": "mind_map.html",
      "title": "Mapping Our Steps",
      "description": "This page gives a birds-eye view of our analysis, where we've come from and where we're headed.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nThe data science life cycle\r\n\r\nThe data science life cycle\r\nIn Hadley Wickam and Garrett Grolemund’s book, R for Data Science, they introduce a model of tools found in the typical data analysis project:\r\nDS Life CycleThis process consists of:\r\nimporting your data into R;\r\ntidying your data by shaping and storing it in a consistent format (luckily, this has largely already been done for us).\r\nOnce the data is tidy and coherent, we will need to:\r\ntransform the data by narrowing in on observations of interest, creating new variables, and calculating summary statistics;\r\nvisualize it to gain new perspective and insights;\r\nmodel the data with a well-defined research question.\r\nAnd this will all be for naught if without effectively communicating our findings.\r\nIn the lab section for Biostat 705 and 707, we’ll be working in a similar loop. To this toolbox, we might also add Workflow Management, which encompasses the bulk of what we do.\r\nThe below visualization aims to provide a visualization of this as we encounter it in-action.\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph boxes_and_circles {\\n      \\n      graph[rankdir = LR, fontname = Helvetica]\\n      \\n      subgraph lab_1 {\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab0 [label = \\\"Lab 0\\\", penwidth = 2.0]\\n      \\n      #Workflow\\n      #Explore\\n      #Transform\\n      \\n      node [shape = box]\\n      \\n      aa [label = \\\"Create workspace\\\"]\\n      ab [label = \\\"Inspect dimensions\\\"]\\n      ac [label = \\\"Generate summary statistics\\\"]\\n      ad [label = \\\"Create derived variable for mothers age\\\"]\\n      ae [label = \\\"Create categorical variable for mothers age\\\"]\\n      \\n      \\n      \\n      # add definition using node IDs\\n      \\n      lab0 -> aa #[label = \\\"Workflow\\\"]\\n      lab0 -> ab #[label = \\\"Explore\\\"]\\n      lab0 -> ac #[label = \\\"Explore\\\"]\\n      lab0 -> ad #[label = \\\"Transform\\\"]\\n      lab0 -> ae #[label = \\\"Transform\\\")]\\n      \\n      #aa -> Workflow\\n      #ab -> Explore\\n      #ac -> Explore\\n      #ad -> Transform\\n      #ae -> Transform\\n      \\n      }\\n      \\n      subgraph lab_1 {\\n    \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab1 [label = \\\"Lab 1\\\", penwidth = 2.0]\\n      \\n      #Explore\\n      #Transform\\n      #Visualize\\n      #Workflow\\n      #Communicate\\n\\n      node [shape = box]\\n\\n      ba [label = \\\"Construct derived variables\\\\nbord5, male, mweight, mbmi\\\"]\\n      bb [label = \\\"Visualize with\\\\nhistograms and boxplots\\\"]\\n      bc [label = \\\"Calculate frequency counts\\\\nand percentages\\\"]\\n      bd [label = \\\"Create data dictionary\\\"]\\n      be [label = \\\"Consider implications of\\\\nmissing values\\\"]\\n      \\n      # edge definitions\\n      \\n      lab1 -> {ba, bb, bc, bd, be}\\n      \\n      #ba -> Transform\\n      #bb -> Visualize\\n      #bc -> Explore\\n      #bd -> Workflow\\n      #be -> Communicate\\n      \\n      \\n      }\\n      \\n      {rank = same; lab0 -> lab1}\\n      \\n      subgraph lab_2 {\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab2 [label = \\\"Lab 2\\\", penwidth = 2.0]\\n      \\n      #Explore\\n      #Transform\\n      #Workflow\\n      #Visualize\\n      #Communicate\\n\\n      node [shape = box]\\n      \\n      ca [label = \\\"Construct derived variables\\\\nsize, belowavg, pnc, rural\\\\neducation, death, and time\\\"]\\n      cb [label = \\\"Update data dictionary\\\"]\\n      cc [label = \\\"Exclude observations where child was alive\\\\nbut less than 60 months of age\\\"]\\n      cd [label = \\\"Generate frequency histograms and\\\\nboxplo1ts for death and time\\\"]\\n      ce [label = \\\"Calculate frequency counts\\\\nandpercentages\\\"]\\n      cf [label = \\\"Consider implications of\\\\nanomalous and missing data\\\"]\\n      \\n      # define edges\\n      \\n      lab2 -> {ca, cb, cc, cd, ce, cf}\\n      \\n      #ca -> Transform\\n      #cb -> Workflow\\n      #cc -> Visualize\\n      #cd -> Explore\\n      #ce -> Explore\\n      #cf -> Communicate\\n      \\n      }\\n      \\n      {rank = same; lab1 -> lab2}\\n      \\n      subgraph lab_3 {\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab3 [label = \\\"Lab 3\\\", penwidth = 2.0]\\n      \\n      #Explore\\n      #Workflow\\n      #Communicate\\n      #Model\\n\\n      node [shape = box]\\n      \\n      da [label = \\\"Define research question:\\\\nWhat are the factors that influence\\\\nthe outcome of child mortality by 5 years of age?\\\"]\\n      db [label = \\\"Generate statistics\\\\nof continuous variables\\\\nmbmi and mage, by mortality status\\\"]\\n      dc [label = \\\"Generate stratified frequency counts and\\\\npercentages of categorical variables, by mortality status\\\"]\\n      dd [label = \\\"Calculate T-tests (continuous vars)\\\\nand Chi-square tests (categorical vars) across stratified levels\\\"]\\n      de [label = \\\"Generate measures of association\\\\n(RD, RR, OR) of exposures and outcomes\\\"]\\n      \\n      df [label = \\\"Interpret results\\\"]\\n      \\n      # define edges\\n      \\n      lab3 -> {da, db, dc, dd, de, df}\\n      \\n      #da -> Workflow\\n      #db -> Explore\\n      #dc -> Explore\\n      #dd -> Model\\n      #de -> Model\\n      #df -> Communicate\\n      \\n      }\\n      \\n      {rank = same; lab2 -> lab3}\\n      \\n      \\n\\n      subgraph lab_4 {\\n    \\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab4 [label = \\\"Lab 4\\\", penwidth = 2.0]\\n      \\n            \\n      #Explore\\n      #Communicate\\n      #Model\\n\\n      node [shape = box]\\n      \\n      ea [label = \\\"Calculate measures of association (RD, RR) between\\\\nbirth order and child mortality by 5 years\\\\nwithin strata of other variables\\\"]\\n      eb [label = \\\"Test for confounding and effect measure modification\\\\ndue to stratifying variables\\\"]\\n      ec [label = \\\"Interpret results\\\"]\\n\\n      \\n      # define edges\\n      \\n      lab4 -> {ea, eb, ec}\\n      \\n      #ea -> Explore\\n      #eb -> Model\\n      #ec -> Communicate\\n      \\n      }\\n      \\n      {rank = same; lab3 -> lab4}\\n      \\n      }\\n    \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:38-04:00"
    },
    {
      "path": "mind_map_first.html",
      "title": "Mapping Our Steps",
      "description": "This page gives a birds-eye view of our analysis, where we've come from and where we're headed.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph lab_0 {\\n      \\n      graph [rankdir = LR]\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab0 [label = \\\"Lab 0\\\"]\\n      \\n      Workflow\\n      Explore\\n      Transform\\n      \\n      node [shape = box]\\n      \\n      a [label = \\\"Create workspace\\\"]\\n      b [label = \\\"Inspect dimensions\\\"]\\n      c [label = \\\"Generate summary statistics\\\"]\\n      d [label = \\\"Create derived variable for mothers age\\\"]\\n      e [label = \\\"Create categorical variable for mothers age\\\"]\\n      \\n      \\n      \\n      # add definition using node IDs\\n      \\n      lab0 -> {a, b, c, d, e}\\n      \\n      a -> Workflow\\n      b -> Explore\\n      c -> Explore\\n      d -> Transform\\n      e -> Transform\\n      \\n      }\\n\\n    \\n      \\n      \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph lab_1 {\\n      \\n      graph [rankdir = LR]\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab1 [label = \\\"Lab 1\\\"]\\n      \\n      Explore\\n      Transform\\n      Visualize\\n      Workflow\\n      Communicate\\n\\n      node [shape = box]\\n\\n      a [label = \\\"Construct derived variables\\\\nbord5, male, mweight, mbmi\\\"]\\n      b [label = \\\"Visualize with\\\\nhistograms and boxplots\\\"]\\n      c [label = \\\"Calculate frequency counts\\\\nand percentages\\\"]\\n      d [label = \\\"Create data dictionary\\\"]\\n      e [label = \\\"Consider implications of\\\\nmissing values\\\"]\\n      \\n      # edge definitions\\n      \\n      lab1 -> {a, b, c, d, e}\\n      \\n      a -> Transform\\n      b -> Visualize\\n      c -> Explore\\n      d -> Workflow\\n      e -> Communicate\\n      \\n      \\n      }\\n      \\n      \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph lab_2 {\\n      \\n      graph [rankdir = LR]\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab2 [label = \\\"Lab 2\\\"]\\n      \\n      Explore\\n      Transform\\n      Workflow\\n      Visualize\\n      Communicate\\n\\n      node [shape = box]\\n      \\n      a [label = \\\"Construct derived variables\\\\nsize, belowavg, pnc, rural\\\\neducation, death, and time\\\"]\\n      b [label = \\\"Update data dictionary\\\"]\\n      c [label = \\\"Exclude observations where child was alive\\\\nbut less than 60 months of age\\\"]\\n      d [label = \\\"Generate frequency histograms and\\\\nboxplo1ts for death and time\\\"]\\n      e [label = \\\"Calculate frequency counts\\\\nandpercentages\\\"]\\n      f [label = \\\"Consider implications of\\\\nanomalous and missing data\\\"]\\n      \\n      # define edges\\n      \\n      lab2 -> {a, b, c, d, e, f}\\n      \\n      a -> Transform\\n      b -> Workflow\\n      c -> Visualize\\n      d -> Explore\\n      e -> Explore\\n      f -> Communicate\\n      \\n      }\\n      \\n      \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph lab_3 {\\n      \\n      graph [rankdir = LR]\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab3 [label = \\\"Lab 3\\\"]\\n      \\n      Explore\\n      Workflow\\n      Communicate\\n      Model\\n\\n      node [shape = box]\\n      \\n      a [label = \\\"Define research question:\\\\nWhat are the factors that influence\\\\nthe outcome of child mortality by 5 years of age?\\\"]\\n      b [label = \\\"Generate statistics\\\\nof continuous variables\\\\nmbmi and mage, by mortality status\\\"]\\n      c [label = \\\"Generate stratified frequency counts and\\\\npercentages of categorical variables, by mortality status\\\"]\\n      d [label = \\\"Calculate T-tests (continuous vars)\\\\nand Chi-square tests (categorical vars) across stratified levels\\\"]\\n      e [label = \\\"Generate measures of association\\\\n(RD, RR, OR) of exposures and outcomes\\\"]\\n      \\n      f [label = \\\"Interpret results\\\"]\\n      \\n      # define edges\\n      \\n      lab3 -> {a, b, c, d, e, f}\\n      \\n      a -> Workflow\\n      b -> Explore\\n      c -> Explore\\n      d -> Model\\n      e -> Model\\n      f -> Communicate\\n      \\n      }\\n      \\n      \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n{\"x\":{\"diagram\":\"\\n\\n      digraph lab_4 {\\n      \\n      graph [rankdir = LR]\\n      \\n      # adding node statements\\n      \\n      node [shape = circle]\\n      \\n      lab4 [label = \\\"Lab 4\\\"]\\n      \\n            \\n      Explore\\n      Communicate\\n      Model\\n\\n      node [shape = box]\\n      \\n      a [label = \\\"Calculate measures of association (RD, RR) between\\\\nbirth order and child mortality by 5 years\\\\nwithin strata of other variables\\\"]\\n      b [label = \\\"Test for confounding and effect measure modification\\\\ndue to stratifying variables\\\"]\\n      c [label = \\\"Interpret results\\\"]\\n\\n      \\n      # define edges\\n      \\n      lab4 -> {a, b, c}\\n      \\n      a -> Explore\\n      b -> Model\\n      c -> Communicate\\n      \\n      }\\n      \\n      \",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:39-04:00"
    },
    {
      "path": "submit.html",
      "title": "Lab Submission Guidelines",
      "description": "Submit your lab according to these guidelines to ensure you receive full points.\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nMaterials to submit\r\nNotes:\r\nSubmitting\r\nRounding\r\n\r\nGrading:\r\n\r\nSubmit your documents electronically via the SAKAI DropBox by 14:00 ET on the date given for each respective lab (SAKAI time-stamps DropBox submissions).\r\nMaterials to submit\r\nR Markdown (.Rmd) file with:\r\nyour name in the YAML header\r\nrequisite code under each task subheading\r\n\r\n.html file - must have run without error\r\nExcel (.xls/.xlsx) file with tables (TODO: Sakai entry for table answers?)\r\nNotes:\r\nSubmitting\r\nThe Rmarkdown file should run from start to finish with no errors, including calling in the analysis dataset, and should produce all of the results and graphs to complete this assignment.\r\nPlease name your files with the paradigm LabX_FirstinitialYourlastname.* (e.g. Lab1_LPark.Rmd), so that your lab instructor can identify each Rmarkdown-file.\r\nLate policy: 5 point deduction per 24 hour period past due date and time.\r\nRounding\r\nWhen completing tables, follow the rounding patterns specified below. This pattern will help in grading this assignment.\r\nThis should be obvious, but do not round intermediate values. Only round final answers for submission.\r\nIf rounding for a given table is not specified or not clear, ask your lab instructor for clarification.\r\nUnless specified within the task instructions, use 3 decimal places for risks and differences and 2 decimal places for rates and ratios.\r\nTo aid in our grading of these assignments, the last figure kept should be rounded UP when the first figure dropped is >= 5. For example, in rounding to 2 decimal places, 0.235 should be reported as 0.24 and 0.245 should be reported as 0.25. Note that this method will introduce a small bias to higher numbers, but another method, “rounding-to-even”, confuses many users.\r\nGrading:\r\n(TODO - change this grading guideline?) RMarkdown files will be graded on an all or nothing. If your markdown file runs from start to finish with no errors, you will receive full credit. If it hits an error message, you will receive NO credit (for the purposes of grading, if any “chunk” of code in your file contains special options, we will ask you to resubmit a file omitting them).\r\nR MARKDOWN FILE: Your markdown file MUST have the following components:\r\nan informative YAML header (see guide to Lab 0[TODO])\r\na set of commands calling in all relevant packages\r\na line of code calling in the analysis dataset\r\neach task’s code performed under the appropriate subheading\r\nif a task requires plotting with ggplot2, a line of code saving said plot using ggsave()\r\n\r\nTABLES: a certain number of points are allocated for each item. Errors include but are not limited to: incorrect values, omissions, and inappropriate rounding. For ease of grading, please do not alter the dimensions of any table. If you are confused on which values go where, please reach out to us for clarification.\r\nSHORT ANSWER QUESTIONS: will generally be graded as follows: 20% of allocated points for some sign of sentience; 40% of allocated points for getting at least part of the answer; 60% of allocated points for a pretty good answer; 80% of allocated points for an excellent, solid answer; 100% of allocated points for an out-of-the-ballpark answer.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-27T16:03:40-04:00"
    }
  ],
  "collections": []
}
